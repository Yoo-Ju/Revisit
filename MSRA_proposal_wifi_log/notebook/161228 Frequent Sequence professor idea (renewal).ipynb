{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MARKDOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymining import seqmining\n",
    "import numpy as np\n",
    "from scipy.special import entr\n",
    "from collections import defaultdict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seqs = [[[['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], [155, 129, 38, 19], 1, 1]], [[['out', '1f'], [8, 25], [160, 158], [152, 133], 1, 2]], [[['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], [400, 48, 235, 38, 100, 97, 1, 1, 1, 1], 0, 3]],[[['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], [157, 129, 38, 19], 1, 4]], [[['out', '1f'], [7, 25], [160, 158], [153, 133], 1, 5]], [[['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], [401, 48, 235, 38, 100, 97, 1, 1, 1, 1], 0, 6]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def interval(tupp):\n",
    "    tup = tuple()\n",
    "    if tupp[1] == 0:\n",
    "        tup = (tupp[0], 'a')\n",
    "    elif tupp[1] < 10:\n",
    "        tup = (tupp[0], 'b')\n",
    "    elif tupp[1] < 100:\n",
    "        tup = (tupp[0], 'c')\n",
    "    elif tupp[1] < 1000:\n",
    "        tup = (tupp[0], 'd')\n",
    "    elif tupp[1] > 1000:\n",
    "        tup = (tupp[0], 'e')\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def temporalinterval(num):\n",
    "#     num = int(num)\n",
    "    res = 0\n",
    "    if num == 0:\n",
    "        res = 'zero'\n",
    "    elif num < 10:\n",
    "        res = 'veryshort'\n",
    "    elif num < 100:\n",
    "        res = 'short'\n",
    "    elif num < 1000:\n",
    "        res = 'medium'\n",
    "    elif num > 1000:\n",
    "        res = 'long'\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## Original without temporal annotation\n",
    "\n",
    "# def _local_freq_items(sdb, prefix, min_support):\n",
    "#     items = defaultdict(int)  ## for support\n",
    "#     items2 = defaultdict(int)  ## for revisit_intention_support\n",
    "#     freq_items = []\n",
    "#     for entry in sdb:\n",
    "#         visited = set()\n",
    "#         for elemento in entry[0]:\n",
    "#             if elemento not in visited:\n",
    "# #                 element = interval(elemento)\n",
    "#                 element = elemento\n",
    "#                 items[element] += 1\n",
    "#                 items2[element] += entry[-1]\n",
    "#                 visited.add(element)\n",
    "#     print(items)\n",
    "#     print(items2)\n",
    "#     print(visited)\n",
    "#     # Sorted is optional. Just useful for debugging for now.\n",
    "#     for item in items:\n",
    "#         support = items[item] ## support\n",
    "#         support2 = items2[item] ## revisit_intention\n",
    "#         if support >= min_support:\n",
    "#             freq_items.append([item, support, support2])\n",
    "#     return freq_items\n",
    "\n",
    "# # locally_frequents = _local_freq_items(seqs, [['out-medium', '1f-medium'], [5]], 2)\n",
    "\n",
    "# locally_frequents = _local_freq_items(seqs, 'prefix', 2)\n",
    "# locally_frequents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry [['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1]\n",
      "entry [['out', '1f'], [8, 25], [160, 158], 1]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0]\n",
      "entry [['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1]\n",
      "entry [['out', '1f'], [7, 25], [160, 158], 1]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('veryshort', 'in'), 2, 0],\n",
       " [('veryshort', '1f'), 2, 0],\n",
       " [('medium', '1f'), 4, 2],\n",
       " [('zero', 'out'), 1, 0],\n",
       " [('short', 'in'), 2, 2],\n",
       " [('medium', '2f'), 2, 0],\n",
       " [('medium', 'in'), 2, 0],\n",
       " [('short', '1f'), 2, 2],\n",
       " [('veryshort', 'out'), 5, 4]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With temporal annotation (temporal=True)\n",
    "\n",
    "def _local_freq_items2(sdb, min_support, temporal):\n",
    "    items = defaultdict(int)  ## for support\n",
    "    items2 = defaultdict(int)  ## for revisit_intention_support\n",
    "    freq_items = []\n",
    "    if temporal == True:\n",
    "        for sequence in sdb:\n",
    "            visited = set()\n",
    "            for entry in sequence: \n",
    "#                 print('entry', entry)\n",
    "                for i in range(len(entry[0])):\n",
    "                    if (temporalinterval(entry[1][i]), entry[0][i]) not in visited:\n",
    "                        element = (temporalinterval(entry[1][i]), entry[0][i])\n",
    "                        items[element] += 1\n",
    "                        items2[element] += entry[-1]\n",
    "                        visited.add(element)\n",
    "    if temporal == False:\n",
    "        for sequence in sdb:\n",
    "            visited = set()\n",
    "            for entry in sequence:\n",
    "                for i in range(len(entry[0])):\n",
    "                    if entry[0][i] not in visited:     ## entry[0][i] = elemento\n",
    "                        element = entry[0][i]\n",
    "                        items[element] += 1\n",
    "                        items2[element] += entry[-1]\n",
    "                        visited.add(element)  \n",
    "\n",
    "    # Sorted is optional. Just useful for debugging for now.\n",
    "    for item in items:\n",
    "        support = items[item] ## support\n",
    "        support2 = items2[item] ## revisit_intention\n",
    "        if support >= min_support:\n",
    "            freq_items.append([item, support, support2])\n",
    "            \n",
    "    return freq_items\n",
    "\n",
    "locally_frequents = _local_freq_items2(seqs, 1, True)\n",
    "locally_frequents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[['1f'], [40], [59], 1], [[], [], [], 1]], [[['in', '1f', 'in', '1f', 'in', '2f'], [99, 101, 201, 301, 401, 501], [199, 198, 202, 302, 402, 502], 0], [['in', '1f', 'in', '2f'], [100, 200, 300, 400], [101, 201, 301, 401], 0], [['in', '2f'], [100, 200], [101, 201], 0]], [[['1f'], [40], [59], 1], [[], [], [], 1]], [[['in', '1f', 'in', '1f', 'in', '2f'], [99, 101, 201, 301, 401, 501], [199, 198, 202, 302, 402, 502], 0], [['in', '1f', 'in', '2f'], [100, 200, 300, 400], [101, 201, 301, 401], 0], [['in', '2f'], [100, 200], [101, 201], 0]]]\n",
      "[[[['1f', 'in', '2f'], [100, 200, 300], [101, 201, 301], 0], [['2f'], [100], [101], 0], [['1f', 'in', '2f'], [100, 200, 300], [101, 201, 301], 0], [['2f'], [100], [101], 0], [['2f'], [100], [101], 0]], [[['1f', 'in', '2f'], [100, 200, 300], [101, 201, 301], 0], [['2f'], [100], [101], 0], [['1f', 'in', '2f'], [100, 200, 300], [101, 201, 301], 0], [['2f'], [100], [101], 0], [['2f'], [100], [101], 0]]]\n",
      "[[[[], [], [], 0], [[], [], [], 0], [[], [], [], 0], [[], [], [], 0], [[], [], [], 0]], [[[], [], [], 0], [[], [], [], 0], [[], [], [], 0], [[], [], [], 0], [[], [], [], 0]]]\n"
     ]
    }
   ],
   "source": [
    "def _project(sdb, prefix):\n",
    "#     print('---------: sdb')\n",
    "#     print(sdb)\n",
    "#     print()\n",
    "    new_sdb = []\n",
    "    if not prefix:\n",
    "        return sdb\n",
    "    current_prefix_item = prefix[-1]\n",
    "#     print(current_prefix_item)\n",
    "#     print( )\n",
    "    for sequence in sdb:\n",
    "        lol = []\n",
    "        for entry in sequence:\n",
    "#             print('entry', entry)\n",
    "            for j in range(len(entry[0])):\n",
    "                projection = None\n",
    "                if entry[0][j] == current_prefix_item[-1]:   ## temporalinterval(entry[1][i])ww.n\n",
    "                    if temporalinterval(entry[1][j]) == current_prefix_item[0]:\n",
    "                        projection = [entry[0][j + 1:], [x-entry[1][j] for x in entry[1][j + 1:]], [x-entry[1][j] for x in entry[2][j + 1:]], entry[-1]]\n",
    "                        lol.append(projection)\n",
    "            \n",
    "        if lol:\n",
    "            new_sdb.append(lol)\n",
    "#     print(len(new_sdb))\n",
    "    return new_sdb\n",
    "\n",
    "seqs2 = _project(seqs, [('medium', '1f')])\n",
    "print(seqs2)\n",
    "\n",
    "seqs3 = _project(seqs2, [('medium', '1f'), ('medium', 'in')])\n",
    "print(seqs3)\n",
    "\n",
    "seqs4 = _project(seqs3, [('medium', '1f'), ('medium', 'in'), ('medium', '2f')])\n",
    "print(seqs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sdb = seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('veryshort', 'in'), 2, 0],\n",
       " [('veryshort', '1f'), 2, 0],\n",
       " [('medium', '1f'), 4, 2],\n",
       " [('zero', 'out'), 1, 0],\n",
       " [('short', 'in'), 2, 2],\n",
       " [('medium', '2f'), 2, 0],\n",
       " [('medium', 'in'), 2, 0],\n",
       " [('short', '1f'), 2, 2],\n",
       " [('veryshort', 'out'), 5, 4]]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locally_frequents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1, 1]], [[['out', '1f'], [8, 25], [160, 158], 1, 2]], [[['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 3]], [[['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1, 4]], [[['out', '1f'], [7, 25], [160, 158], 1, 5]], [[['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 6]]]\n",
      "\n",
      "[('veryshort', 'in')]\n",
      "entry [['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1, 1]\n",
      "entry [['out', '1f'], [8, 25], [160, 158], 1, 2]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 3]\n",
      "entry [['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1, 4]\n",
      "entry [['out', '1f'], [7, 25], [160, 158], 1, 5]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 6]\n",
      "new_prefix [('veryshort', 'in')]\n",
      "new_sdb [[[['1f', 'in', '1f', 'in', '1f', 'in', '2f'], [196, 295, 297, 397, 497, 597, 697], [234, 395, 394, 398, 498, 598, 698], 3]], [[['1f', 'in', '1f', 'in', '1f', 'in', '2f'], [196, 295, 297, 397, 497, 597, 697], [234, 395, 394, 398, 498, 598, 698], 6]]]\n",
      "new_sdb 2\n",
      "[('veryshort', '1f')]\n",
      "entry [['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1, 1]\n",
      "entry [['out', '1f'], [8, 25], [160, 158], 1, 2]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 3]\n",
      "entry [['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1, 4]\n",
      "entry [['out', '1f'], [7, 25], [160, 158], 1, 5]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 6]\n",
      "new_prefix [('veryshort', '1f')]\n",
      "new_sdb [[[['in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [3, 199, 298, 300, 400, 500, 600, 700], [238, 237, 398, 397, 401, 501, 601, 701], 3]], [[['in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [3, 199, 298, 300, 400, 500, 600, 700], [238, 237, 398, 397, 401, 501, 601, 701], 6]]]\n",
      "new_sdb 2\n",
      "[('medium', '1f')]\n",
      "entry [['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1, 1]\n",
      "entry [['out', '1f'], [8, 25], [160, 158], 1, 2]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 3]\n",
      "entry [['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1, 4]\n",
      "entry [['out', '1f'], [7, 25], [160, 158], 1, 5]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 6]\n",
      "new_prefix [('medium', '1f')]\n",
      "new_sdb [[[['1f'], [40], [59], 1], [[], [], [], 1]], [[['in', '1f', 'in', '1f', 'in', '2f'], [99, 101, 201, 301, 401, 501], [199, 198, 202, 302, 402, 502], 3], [['in', '1f', 'in', '2f'], [100, 200, 300, 400], [101, 201, 301, 401], 3], [['in', '2f'], [100, 200], [101, 201], 3]], [[['1f'], [40], [59], 4], [[], [], [], 4]], [[['in', '1f', 'in', '1f', 'in', '2f'], [99, 101, 201, 301, 401, 501], [199, 198, 202, 302, 402, 502], 6], [['in', '1f', 'in', '2f'], [100, 200, 300, 400], [101, 201, 301, 401], 6], [['in', '2f'], [100, 200], [101, 201], 6]]]\n",
      "new_sdb 4\n",
      "[('zero', 'out')]\n",
      "entry [['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1, 1]\n",
      "entry [['out', '1f'], [8, 25], [160, 158], 1, 2]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 3]\n",
      "entry [['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1, 4]\n",
      "entry [['out', '1f'], [7, 25], [160, 158], 1, 5]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 6]\n",
      "new_prefix [('zero', 'out')]\n",
      "new_sdb [[[['1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [2, 5, 201, 300, 302, 402, 502, 602, 702], [50, 240, 239, 400, 399, 403, 503, 603, 703], 6]]]\n",
      "new_sdb 1\n",
      "[('short', 'in')]\n",
      "entry [['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1, 1]\n",
      "entry [['out', '1f'], [8, 25], [160, 158], 1, 2]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 3]\n",
      "entry [['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1, 4]\n",
      "entry [['out', '1f'], [7, 25], [160, 158], 1, 5]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 6]\n",
      "new_prefix [('short', 'in')]\n",
      "new_sdb [[[['1f', '1f'], [70, 110], [108, 129], 1]], [[['1f', '1f'], [70, 110], [108, 129], 4]]]\n",
      "new_sdb 2\n",
      "[('medium', '2f')]\n",
      "entry [['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1, 1]\n",
      "entry [['out', '1f'], [8, 25], [160, 158], 1, 2]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 3]\n",
      "entry [['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1, 4]\n",
      "entry [['out', '1f'], [7, 25], [160, 158], 1, 5]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 6]\n",
      "new_prefix [('medium', '2f')]\n",
      "new_sdb [[[[], [], [], 3]], [[[], [], [], 6]]]\n",
      "new_sdb 2\n",
      "[('medium', 'in')]\n",
      "entry [['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1, 1]\n",
      "entry [['out', '1f'], [8, 25], [160, 158], 1, 2]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 3]\n",
      "entry [['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1, 4]\n",
      "entry [['out', '1f'], [7, 25], [160, 158], 1, 5]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 6]\n",
      "new_prefix [('medium', 'in')]\n",
      "new_sdb [[[['1f', 'in', '1f', 'in', '2f'], [2, 102, 202, 302, 402], [99, 103, 203, 303, 403], 3], [['1f', 'in', '2f'], [100, 200, 300], [101, 201, 301], 3], [['2f'], [100], [101], 3]], [[['1f', 'in', '1f', 'in', '2f'], [2, 102, 202, 302, 402], [99, 103, 203, 303, 403], 6], [['1f', 'in', '2f'], [100, 200, 300], [101, 201, 301], 6], [['2f'], [100], [101], 6]]]\n",
      "new_sdb 2\n",
      "[('short', '1f')]\n",
      "entry [['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1, 1]\n",
      "entry [['out', '1f'], [8, 25], [160, 158], 1, 2]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 3]\n",
      "entry [['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1, 4]\n",
      "entry [['out', '1f'], [7, 25], [160, 158], 1, 5]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 6]\n",
      "new_prefix [('short', '1f')]\n",
      "new_sdb [[[[], [], [], 2]], [[[], [], [], 5]]]\n",
      "new_sdb 2\n",
      "[('veryshort', 'out')]\n",
      "entry [['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1, 1]\n",
      "entry [['out', '1f'], [8, 25], [160, 158], 1, 2]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 3]\n",
      "entry [['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1, 4]\n",
      "entry [['out', '1f'], [7, 25], [160, 158], 1, 5]\n",
      "entry [['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 6]\n",
      "new_prefix [('veryshort', 'out')]\n",
      "new_sdb [[[['in', '1f', '1f'], [25, 95, 135], [154, 133, 154], 1]], [[['1f'], [17], [150], 2]], [[['1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 4, 200, 299, 301, 401, 501, 601, 701], [49, 239, 238, 399, 398, 402, 502, 602, 702], 3]], [[['in', '1f', '1f'], [27, 97, 137], [156, 135, 156], 4]], [[['1f'], [18], [151], 5]]]\n",
      "new_sdb 5\n"
     ]
    }
   ],
   "source": [
    "print(sdb)\n",
    "print()\n",
    "\n",
    "for (item, support1, support2) in locally_frequents:\n",
    "    new_prefix = [] + [item,]\n",
    "    print(new_prefix)\n",
    "    new_sdb = _project(sdb, new_prefix)\n",
    "    print('new_prefix', new_prefix)\n",
    "    print('new_sdb', new_sdb)\n",
    "    print('new_sdb', len(new_sdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1]],\n",
       " [[['out', '1f'], [8, 25], [160, 158], 1]],\n",
       " [[['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'],\n",
       "   [1, 2, 5, 201, 300, 302, 402, 502, 602, 702],\n",
       "   [401, 50, 240, 239, 400, 399, 403, 503, 603, 703],\n",
       "   0]],\n",
       " [[['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1]],\n",
       " [[['out', '1f'], [7, 25], [160, 158], 1]],\n",
       " [[['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'],\n",
       "   [0, 2, 5, 201, 300, 302, 402, 502, 602, 702],\n",
       "   [401, 50, 240, 239, 400, 399, 403, 503, 603, 703],\n",
       "   0]]]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[['out', 'in', '1f', '1f'], [5, 30, 100, 140], [160, 159, 138, 159], 1, 1]], [[['out', '1f'], [8, 25], [160, 158], 1, 2]], [[['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [1, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 3]], [[['out', 'in', '1f', '1f'], [3, 30, 100, 140], [160, 159, 138, 159], 1, 4]], [[['out', '1f'], [7, 25], [160, 158], 1, 5]], [[['out', '1f', 'in', '1f', 'in', '1f', 'in', '1f', 'in', '2f'], [0, 2, 5, 201, 300, 302, 402, 502, 602, 702], [401, 50, 240, 239, 400, 399, 403, 503, 603, 703], 0, 6]]]\n",
      "locally frequents [[('medium', '1f'), 4, 2], [('veryshort', 'out'), 5, 4]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-df3e416e883e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mfreq_seq_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-166-df3e416e883e>\u001b[0m in \u001b[0;36mfreq_seq_enum\u001b[0;34m(sequences, min_support)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfreq_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mincludingSeqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0m_freq_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_support\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludingSeqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfreq_seqs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-166-df3e416e883e>\u001b[0m in \u001b[0;36m_freq_seq\u001b[0;34m(sdb, prefix, prefix_support, revisit_support, min_support, freq_seqs, includingSeqs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#         print ('not locally frequents', sdb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludingSeqs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocally_frequents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mnew_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mnew_sdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "### kinda old\n",
    "### 이 코드에서 계산중에 같이 collect할 수 있을거라 생각했는데 , 포기.\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def freq_seq_enum(sequences, min_support):\n",
    "    '''\n",
    "       Enumerates all frequent sequences.\n",
    "       :param sequences: A sequence of sequences.\n",
    "       :param min_support: The minimal support of a set to be included.\n",
    "       :rtype: A set of (frequent_sequence, support).\n",
    "    '''\n",
    "    freq_seqs = []\n",
    "    includingSeqs = {}\n",
    "    _freq_seq(sequences, [], 0, 0, min_support, freq_seqs, includingSeqs)\n",
    "    return freq_seqs\n",
    "\n",
    "\n",
    "def _freq_seq(sdb, prefix, prefix_support, revisit_support, min_support, freq_seqs, includingSeqs):\n",
    "    if prefix:\n",
    "        print('prefix: yes', prefix)\n",
    "        print([prefix, prefix_support, revisit_support])\n",
    "        freq_seqs.append([prefix, prefix_support, revisit_support, includingSeqs])\n",
    "        print('freq seqs', freq_seqs)\n",
    "        print()\n",
    "    locally_frequents = _local_freq_items2(sdb, min_support, True)\n",
    "    print('locally frequents', locally_frequents)\n",
    "    if not locally_frequents:\n",
    "#         print ('not locally frequents', sdb)\n",
    "        return\n",
    "    for (item, support1, support2, includingSeqs) in locally_frequents:\n",
    "        new_prefix = prefix + [item,]\n",
    "        new_sdb = _project(sdb, new_prefix)\n",
    "#         print('new_prefix', new_prefix)\n",
    "#         print('new_sdb', new_sdb)\n",
    "        _freq_seq(new_sdb, new_prefix, support1, support2, min_support, freq_seqs, includingSeqs)\n",
    "\n",
    "\n",
    "## With temporal annotation (temporal=True)\n",
    "def _local_freq_items2(sdb, min_support, temporal):\n",
    "    items = defaultdict(int)  ## for support\n",
    "    items2 = defaultdict(int)  ## for revisit_intention_support\n",
    "    includingSeqs = defaultdict(dict)\n",
    "    freq_items = []\n",
    "    if temporal == True:\n",
    "        for sequence in sdb:\n",
    "            visited = set()\n",
    "            for entry in sequence: \n",
    "                for i in range(len(entry[0])):\n",
    "                    element = (temporalinterval(entry[1][i]), entry[0][i])\n",
    "                    if element not in visited:\n",
    "                        items[element] += 1\n",
    "                        items2[element] += entry[3]\n",
    "                        visited.add(element)\n",
    "    if temporal == False:\n",
    "        for sequence in sdb:\n",
    "            visited = set()\n",
    "            for entry in sequence:\n",
    "                for i in range(len(entry[0])):\n",
    "                    if entry[0][i] not in visited:     ## entry[0][i] = elemento\n",
    "                        element = entry[0][i]\n",
    "                        items[element] += 1\n",
    "                        items2[element] += entry[3]\n",
    "                        visited.add(element)  \n",
    "\n",
    "    # Sorted is optional. Just useful for debugging for now.\n",
    "    for item in items:\n",
    "        support = items[item] ## support\n",
    "        support2 = items2[item] ## revisit_intention\n",
    "        if support >= min_support:\n",
    "            freq_items.append([item, support, support2])\n",
    "            \n",
    "    return freq_items\n",
    "\n",
    "# locally_frequents = _local_freq_items2(seqs, 1, True)\n",
    "# locally_frequents\n",
    "\n",
    "\n",
    "\n",
    "def _project(sdb, prefix):\n",
    "    new_sdb = []\n",
    "    if not prefix:\n",
    "        return sdb\n",
    "    current_prefix_item = prefix[-1]\n",
    "    for sequence in sdb:\n",
    "        lol = []\n",
    "        for entry in sequence:\n",
    "            print('entry', entry)\n",
    "            for j in range(len(entry[0])):\n",
    "                projection = None\n",
    "                if entry[0][j] == current_prefix_item[-1]:   ## temporalinterval(entry[1][i])ww.n\n",
    "                    if temporalinterval(entry[1][j]) == current_prefix_item[0]:\n",
    "                        projection = [entry[0][j + 1:], [x-entry[1][j] for x in entry[1][j + 1:]], [x-entry[1][j] for x in entry[2][j + 1:]], entry[-1]] \n",
    "                        ## 마지막에 entry를 붙임 - tracking 위해 \n",
    "                        lol.append(projection)\n",
    "            \n",
    "        if lol:\n",
    "            new_sdb.append(lol)\n",
    "#     print(len(new_sdb))\n",
    "    return new_sdb\n",
    "\n",
    "\n",
    "\n",
    "print(seqs)\n",
    "\n",
    "freq_seq_enum(seqs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-27e3f27d2b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0mfreq_seq_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seqs' is not defined"
     ]
    }
   ],
   "source": [
    "### 이 코드에서 계산중에 같이 collect할 수 있을거라 생각했는데 , 포기.\n",
    "from collections import defaultdict\n",
    "\n",
    "def freq_seq_enum(sequences, min_support):\n",
    "    '''Enumerates all frequent sequences.\n",
    "\n",
    "       :param sequences: A sequence of sequences.\n",
    "       :param min_support: The minimal support of a set to be included.\n",
    "       :rtype: A set of (frequent_sequence, support).\n",
    "    '''\n",
    "    freq_seqs = []\n",
    "    includingSeqs = defaultdict(dict)\n",
    "    _freq_seq(sequences, [], 0, 0, min_support, freq_seqs, includingSeqs)\n",
    "    return freq_seqs\n",
    "\n",
    "\n",
    "def _freq_seq(sdb, prefix, prefix_support, revisit_support, min_support, freq_seqs, includingSeqs):\n",
    "    if prefix:\n",
    "#         print('prefix: yes', prefix)\n",
    "#         print([prefix, prefix_support, revisit_support])\n",
    "        freq_seqs.append([prefix, prefix_support, revisit_support, includingSeqs[prefix[-1]]])\n",
    "#         print('freq seqs', freq_seqs)\n",
    "        includingSeqs = defaultdict(dict)\n",
    "#         print(includingSeqs)\n",
    "#         print()\n",
    "    locally_frequents = _local_freq_items2(sdb, min_support, True, includingSeqs)\n",
    "#     print('locally frequents', locally_frequents)\n",
    "    if not locally_frequents:\n",
    "#         print ('not locally frequents', sdb)\n",
    "        return\n",
    "    for (item, support1, support2, includingSeqs) in locally_frequents:\n",
    "        new_prefix = prefix + [item,]\n",
    "        new_sdb = _project(sdb, new_prefix)\n",
    "#         print('new_prefix', new_prefix)\n",
    "#         print('new_sdb', new_sdb)\n",
    "        _freq_seq(new_sdb, new_prefix, support1, support2, min_support, freq_seqs, includingSeqs)\n",
    "\n",
    "\n",
    "## With temporal annotation (temporal=True)\n",
    "def _local_freq_items2(sdb, min_support, temporal, includingSeqs):\n",
    "    items = defaultdict(int)  ## for support\n",
    "    items2 = defaultdict(int)  ## for revisit_intention_support\n",
    "#     includingSeqs = defaultdict(dict)\n",
    "#     print(includingSeqs)\n",
    "    freq_items = []\n",
    "    if temporal == True:\n",
    "        for sequence in sdb:\n",
    "            visited = set()\n",
    "            for entry in sequence: \n",
    "                for i in range(len(entry[0])):\n",
    "                    element = (temporalinterval(entry[1][i]), entry[0][i])\n",
    "#                     print(entry, '--', element)\n",
    "#                     print(includingSeqs)\n",
    "                    includingSeqs[element][entry[-1]] = includingSeqs[element].get(entry[-1], 0) + 1\n",
    "                    if element not in visited:\n",
    "                        items[element] += 1\n",
    "#                         print(items2)\n",
    "#                         print(element)\n",
    "#                         print(entry)\n",
    "                        items2[element] += int(entry[-2])\n",
    "                        visited.add(element)\n",
    "    if temporal == False:\n",
    "        for sequence in sdb:\n",
    "            visited = set()\n",
    "            for entry in sequence:\n",
    "                for i in range(len(entry[0])):\n",
    "                    element = entry[0][i]\n",
    "                    includingSeqs[element][entry[-1]] = includingSeqs[element].get(entry[-1], 0) + 1\n",
    "                    if element not in visited:     ## entry[0][i] = elemento\n",
    "                        items[element] += 1\n",
    "                        items2[element] += int(entry[-2])\n",
    "                        visited.add(element)  \n",
    "\n",
    "    # Sorted is optional. Just useful for debugging for now.\n",
    "    for item in items:\n",
    "        support = items[item] ## support\n",
    "        support2 = items2[item] ## revisit_intention\n",
    "        if support >= min_support:\n",
    "            freq_items.append([item, support, support2, includingSeqs])\n",
    "            \n",
    "    return freq_items\n",
    "\n",
    "# locally_frequents = _local_freq_items2(seqs, 1, True)\n",
    "# locally_frequents\n",
    "\n",
    "\n",
    "\n",
    "def _project(sdb, prefix):\n",
    "    new_sdb = []\n",
    "    if not prefix:\n",
    "        return sdb\n",
    "    current_prefix_item = prefix[-1]\n",
    "    for sequence in sdb:\n",
    "        lol = []\n",
    "        for entry in sequence:\n",
    "#             print('entry', entry)\n",
    "            for j in range(len(entry[0])):\n",
    "                projection = None\n",
    "                if entry[0][j] == current_prefix_item[-1]:   ## temporalinterval(entry[1][i])ww.n\n",
    "                    if temporalinterval(entry[1][j]) == current_prefix_item[0]:\n",
    "                        projection = [entry[0][j + 1:], [x-entry[1][j] for x in entry[1][j + 1:]], [x-entry[1][j] for x in entry[2][j + 1:]], entry[-2], entry[-1]] \n",
    "                        ## 마지막에 entry를 붙임 - tracking 위해 \n",
    "                        lol.append(projection)\n",
    "        if lol:\n",
    "            new_sdb.append(lol)\n",
    "#     print(len(new_sdb))\n",
    "#     print('sdb------', new_sdb)\n",
    "    return new_sdb\n",
    "\n",
    "\n",
    "# print(seqs)\n",
    "# print()\n",
    "# print()\n",
    "# print(_project(seqs, [('medium', '1f')]))\n",
    "\n",
    "\n",
    "print(seqs)\n",
    "freq_seq_enum(seqs, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reindexing(q, a, b, dtime, idx, p):\n",
    "    startmp = a[0]\n",
    "    newa = [x-startmp for x in a]\n",
    "    newb = [x-startmp for x in b]\n",
    "    return [[q, newa, newb, dtime, idx, p]]\n",
    "\n",
    "def puttogether(a, b):\n",
    "    if b == 0:\n",
    "        c = 'zero'\n",
    "    elif b < 10:\n",
    "        c = 'veryshort'\n",
    "    elif b < 100:\n",
    "        c = 'short'\n",
    "    elif b < 1000:\n",
    "        c = 'medium'\n",
    "    else:\n",
    "        c = 'long'\n",
    "    return '-'.join([a,c])\n",
    "\n",
    "def add_temporal_sign(x, area):  # Make features like 1f-medium, or 1f-inner-short\n",
    "    idcs = [i for i, y in enumerate(x['traj']) if y in area]\n",
    "    zt = [puttogether(x['traj'][index], x['dwell_time'][index]) for index in idcs] \n",
    "    return zt\n",
    "\n",
    "def getuniqueareas(trajseries):\n",
    "    aggregated_traj = list(itertools.chain.from_iterable(trajseries))\n",
    "    uniqueareas = sorted(list(set(aggregated_traj)))\n",
    "    return uniqueareas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Name: sequencefeaturegenerator2.py\n",
    "Date: 2016-10-25\n",
    "Description: Frequent Sequence 를 찾은 후 Feature로 이용하는 모듈 (faster ver)\n",
    "\n",
    "\n",
    "Input: \n",
    "TO DO: \n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import entr\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def is_subseq(x, y):\n",
    "    it = iter(y)\n",
    "    return all(c in it for c in x)\n",
    "\n",
    "# assert is_subseq('india', 'indonesia')\n",
    "# assert is_subseq('oman', 'romania')\n",
    "# assert is_subseq('mali', 'malawi')\n",
    "# assert is_subseq((''), ('a', 'b', 'c', 'd', 'e'))\n",
    "# assert not is_subseq('mali', 'banana')\n",
    "# assert not is_subseq('ais', 'indonesia')\n",
    "# assert not is_subseq('ca', 'abc')\n",
    "\n",
    "def entropy(prob1, prob2):\n",
    "    return(-prob1*np.log2(prob1)-prob2*np.log2(prob2))\n",
    "\n",
    "def informationGain(a, b, c, d):\n",
    "    ''' \n",
    "    a = (True, 1.0) - Subsequence, Revisit intention      \n",
    "    b = (True, 0.0)       \n",
    "    c = (False, 1.0)    \n",
    "    d = (False, 0.0) \n",
    "    '''\n",
    "    # Entropy before\n",
    "    prob1a = (a+c) / (a+b+c+d)\n",
    "    prob2a = 1-prob1a\n",
    "    entropy_before = entropy(prob1a, prob2a)\n",
    "    \n",
    "    # Entropy after sequence\n",
    "    prob1b = a / (a+b)\n",
    "    prob2b = 1 - prob1b\n",
    "    prob3b = c / (c+d)\n",
    "    prob4b = 1 - prob3b\n",
    "    \n",
    "    entropy1 = entropy(prob1b, prob2b)\n",
    "    entropy2 = entropy(prob3b, prob4b)\n",
    "    entropy_after = (a+b)/(a+b+c+d)*entropy1 + (c+d)/(a+b+c+d)*entropy2\n",
    "    \n",
    "    IG = entropy_before-entropy_after\n",
    "    \n",
    "    return IG\n",
    "\n",
    "\n",
    "\n",
    "def recursivelyFindLongestSequence(aabaaba, new_list):\n",
    "\n",
    "    try:\n",
    "        for item in aabaaba:\n",
    "            testval = 0\n",
    "            for longt in new_list:\n",
    "                testval += is_subseq(item, longt)\n",
    "\n",
    "            if testval == 0:\n",
    "                new_list.append(item)\n",
    "\n",
    "        for item in new_list:\n",
    "            aabaaba.remove(item)\n",
    "\n",
    "\n",
    "        recursivelyFindLongestSequence(aabaaba, new_list)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "### If multiple subsequences have same support, there is a chance to have closed sequence and its subsequence\n",
    "### Here, we only select independent longest sequences by deleting its subs.\n",
    "### Technique used: Chance key, value and removing subs by dynamic programming\n",
    "### Method recursivelyFindLongestSequence is used for the dynamic programming part.\n",
    "### Input: freq_seqs_sample - Output: freqfreqfreq\n",
    "\n",
    "def leavelongest_samesupport(freq_seqs_sample):\n",
    "\n",
    "    freq_seqs_sample2 = {}\n",
    "    for kv in freq_seqs_sample:\n",
    "        freq_seqs_sample2.setdefault((kv[1], kv[2]), []).append(kv[0])\n",
    "\n",
    "    freqfreqfreq = []\n",
    "\n",
    "\n",
    "    for k, v in freq_seqs_sample2.items():\n",
    "        if len(v) > 1:\n",
    "            v = sorted(v, key = len, reverse=True)\n",
    "            new_list = []\n",
    "            new_list.append(tuple(v[0]))\n",
    "            \n",
    "            recursivelyFindLongestSequence(v, new_list) \n",
    "            for item in new_list:\n",
    "                freqfreqfreq.append(tuple((item, k)))\n",
    "        else:\n",
    "            freqfreqfreq.append(tuple((tuple(v[0]), k)))\n",
    "\n",
    "    freqfreqfreq = sorted(freqfreqfreq, key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    return freqfreqfreq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_sortE(df, supportRatio):\n",
    "\n",
    "    ### Extract subsequences with support greater than 200 (from 8886 for this example ~ 2.5%)\n",
    "    seqs = df.apply(lambda x: reindexing(x['traj'], x['ts'], x['ts_end'], x['dwell_time'], x['revisit_intention'], x['index']), axis=1) \n",
    "#     seqs = df.head(10).apply(lambda x: [[x['traj'], x['ts'], x['ts_end'], x['revisit_intention']]], axis=1)\n",
    "\n",
    "    freq_seqs = freq_seq_enum(seqs, seqs.shape[0]*supportRatio)   #0.025 = support ratio\n",
    "\n",
    "    ### Minimum subsequence length == 4  &  sort by support (TODO: parameter)\n",
    "    freq_seqs_sample = []\n",
    "    for x in freq_seqs:\n",
    "        if (len(x[0]) >= 1):\n",
    "    #         if (x[0][0] != 'out') & (x[0][0] != 'in'):\n",
    "            freq_seqs_sample.append(x)\n",
    "    freq_seqs_sample = sorted(freq_seqs_sample, key=lambda tup: tup[1], reverse=True)   \n",
    "#     print(freq_seqs_sample[1])\n",
    "    \n",
    "    \n",
    "    frequency_dict = defaultdict(dict)\n",
    "    for i in freq_seqs_sample:\n",
    "        frequency_dict[tuple(i[0])] = i[-1]  ## element 길이가 1인 걸 tuple화하면 다음과 같이 변한다 -> tuple([('zero', 'out-medium')]) = (('zero', 'out-medium'),)\n",
    "#     print(len(frequency_dict))   ## key: TAS-like seq: (('zero', 'out-medium'), ('long', 'out-medium')) 형태\n",
    "#     print('------dictkeys------')\n",
    "#     print(frequency_dict.keys())\n",
    "#     print(frequency_dict[(('zero', 'out-medium'), ('long', 'out-medium'))])%%!\n",
    "    \n",
    "\n",
    "\n",
    "    ### Leave longest supersequence \n",
    "    longest_sequences_support = leavelongest_samesupport(freq_seqs_sample)\n",
    "#     print()\n",
    "#     print('----longest_sequences_support----')\n",
    "#     print(longest_sequences_support)\n",
    "#     print(longest_sequences_support[1:10])\n",
    "    \n",
    "    print(\"Number of TAS-like frequent sequences having support larger than threshold : \",len(freq_seqs_sample))\n",
    "    print(\"Number of TAS-like frequent closed sequences having support larger than threshold :\", len(longest_sequences_support))\n",
    "    num1 = df.revisit_intention.value_counts().loc[1]\n",
    "    num0 = df.revisit_intention.value_counts().loc[0]\n",
    "\n",
    "    ### Calculate information gain easily\n",
    "    ''' \n",
    "    a = (True, 1.0) - Subsequence, Revisit intention      \n",
    "    b = (True, 0.0)       \n",
    "    c = (False, 1.0)    \n",
    "    d = (False, 0.0) \n",
    "    '''\n",
    "    longest_sequences_support2 = []\n",
    "    \n",
    "    for i in longest_sequences_support:\n",
    "        z = []  \n",
    "        a = i[1][1]  \n",
    "        b = i[1][0] - i[1][1]\n",
    "        c = num1 - a\n",
    "        d = num0 - b\n",
    "        z.append(a)\n",
    "        z.append(b)\n",
    "        z.append(c)\n",
    "        z.append(d)\n",
    "        ig = informationGain(a, b, c, d)\n",
    "        z.append(ig)\n",
    "        longest_sequences_support2.append((i[0], z))\n",
    "#     print('******')\n",
    "#     print(longest_sequences_support2[:30])\n",
    "\n",
    "    igdict = {}\n",
    "    \n",
    "    for traj in longest_sequences_support2:\n",
    "        igdict[tuple(traj[0])] = traj[1]\n",
    "\n",
    "    # print('ig calculation has been done')\n",
    "\n",
    "    ### SortE: Tuples list of sequences(key) and their information gain\n",
    "    sortE = sorted(igdict.items(), key=lambda value: value[1][-1], reverse=True)\n",
    "    return sortE, frequency_dict\n",
    "\n",
    "\n",
    "def generate_seqE(sortE, numFeatures):\n",
    "    seqE = []\n",
    "    for item in sortE[:numFeatures]:\n",
    "        seqE.append(item[0])\n",
    "    return seqE\n",
    "\n",
    "\n",
    "\n",
    "# Sequence feature를 걍 숫자로 표현 - 해당 feature를 가지면 1, 가지지 않으면 0\n",
    "def add_features_frequency(df, seqE, fdict):                   \n",
    "    print(\"Check 2=\",fdict[(('long', 'out-long'), ('zero', 'in-long'))]['16706_ba4d2fd67842a96701f0fe1800c1c214'])\n",
    "#     [('long', 'out-long'), ('long', 'out-medium')]\n",
    "    newdf = df\n",
    "    print(newdf.shape)\n",
    "    for seq in seqE:\n",
    "#         print (seq, \"---\", type(seq))\n",
    "        newdf[seq] = 0\n",
    "    print(newdf.shape)\n",
    "    \n",
    "#     print(seqE)\n",
    "#     print([i for i, j in zip(seqE, list(fdict.keys())) if i == j])\n",
    "#     print(listfdict.keys())\n",
    "    for seq in seqE:\n",
    "#         print('seq: ', seq)\n",
    "#         print(fdict[seq].keys())\n",
    "        for idx in fdict[seq].keys():\n",
    "#             print('idx: ', idx)\n",
    "#             print('val: ', fdict[seq][idx])\n",
    "            newdf.set_value(idx, seq, fdict[seq][idx])\n",
    "#     for idx in df.index:\n",
    "#         for seq in seqE:\n",
    "#             try:\n",
    "#                 df.set_value(idx, seq, fdict[tuple(seq)][idx]) \n",
    "#             except KeyError:\n",
    "#                 df.set_value(idx, seq, 0)\n",
    "                \n",
    "    del df\n",
    "    return newdf\n",
    "\n",
    "# def generateIGFeatureColumns(df, seqE):\n",
    "#     sss = 2001\n",
    "#     for seq in seqE:\n",
    "#         df[sss] = 0\n",
    "#         sss += 1\n",
    "#     for row in df.iterrows():\n",
    "#         for seq_ig in row[1]['seq_ig_ft']:\n",
    "\n",
    "            \n",
    "def add_frequent_sequence_features(df, supportRatio, featureRatio, temporal):\n",
    "    df = df.reset_index()\n",
    "    if temporal == True:\n",
    "        print('Generating feature: By considering dwell_time of each area')\n",
    "        area = getuniqueareas(df.traj)\n",
    "        # print(area)\n",
    "        df['traj'] = df.apply(lambda x: add_temporal_sign(x, area), axis=1)\n",
    "    else:\n",
    "        print('Generating feature: Not considering dwell_time of each area')\n",
    "\n",
    "    sortE, fdict = generate_sortE(df, supportRatio)\n",
    "#     print(fdict.keys())\n",
    "\n",
    "    df = df.set_index(['index'])\n",
    "    numFeatures = int(round(df.shape[0]*featureRatio))\n",
    "    seqE = generate_seqE(sortE, numFeatures)\n",
    "    \n",
    "       \n",
    "    newdf = add_features_frequency(df, seqE, fdict)\n",
    "    \n",
    "    return newdf, fdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature: By considering dwell_time of each area\n",
      "Number of TAS-like frequent sequences having support larger than threshold :  935\n",
      "Number of TAS-like frequent closed sequences having support larger than threshold : 891\n",
      "Check 2= 2\n",
      "(8886, 37)\n",
      "(8886, 215)\n"
     ]
    }
   ],
   "source": [
    "trajs_combined_balanced = pd.read_pickle(\"../data/786/786_trajs_combined_balanced.p\")\n",
    "# generate_sortE(trajs_combined_balanced.head(100), 0.05)\n",
    "finaldf, fdict = add_frequent_sequence_features(trajs_combined_balanced, 0.005, 0.02, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('long', 'out-medium'), ('long', 'out-long'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     8724\n",
       "1       78\n",
       "2       22\n",
       "3       13\n",
       "4       13\n",
       "9        6\n",
       "8        6\n",
       "5        5\n",
       "6        4\n",
       "20       3\n",
       "13       2\n",
       "12       2\n",
       "28       1\n",
       "15       1\n",
       "19       1\n",
       "11       1\n",
       "29       1\n",
       "7        1\n",
       "32       1\n",
       "31       1\n",
       "Name: ((long, out-medium), (long, out-long)), dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(finaldf.columns)[41])\n",
    "finaldf[list(finaldf.columns)[41]].value_counts()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
