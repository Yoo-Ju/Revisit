{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why keras?\n",
    "\n",
    "Why RNN & LSTM? 블로그 포스트들과 우리 연구와의 관련성\n",
    "\n",
    "* http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "    * Sequences input -> Positive or negative output도 처리 가능\n",
    "    * 예제: Minimal character level RNN language model in python/numpy:\n",
    "    https://gist.github.com/karpathy/d4dee566867f8291f086\n",
    "* http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "placeNum = str(786)\n",
    "# statistical_picklePath2 = \"../code/data/\"+placeNum+\"/\"+placeNum+\"_mpframe3.p\"\n",
    "statistical_picklePath2 = \"../data/\"+placeNum+\"/\"+placeNum+\"_trajs_combined_balanced.p\"\n",
    "df = pd.read_pickle(statistical_picklePath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df[['traj', 'ts', 'dwell_time', 'time_start', 'ts_end', 'revisit_intention']]  #  'time_end',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traj</th>\n",
       "      <th>ts</th>\n",
       "      <th>dwell_time</th>\n",
       "      <th>time_start</th>\n",
       "      <th>ts_end</th>\n",
       "      <th>revisit_intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16767_25e9517c47319ab64486403f94348dd6</th>\n",
       "      <td>[out, in, 2f, 2f-inner, 1f]</td>\n",
       "      <td>[1448711070, 1448711259, 1448711286, 144871128...</td>\n",
       "      <td>[314, 125, 98, 98, 65]</td>\n",
       "      <td>[20:44:30, 20:47:39, 20:48:06, 20:48:06, 20:48...</td>\n",
       "      <td>[1448711384, 1448711384, 1448711384, 144871138...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16955_53f0a6276486cc80405cf534d913fcbb</th>\n",
       "      <td>[out, in, 1f, 1f-right, 1f-left]</td>\n",
       "      <td>[1464939171, 1464939171, 1464939171, 146493923...</td>\n",
       "      <td>[266, 263, 263, 198, 156]</td>\n",
       "      <td>[16:32:51, 16:32:51, 16:32:51, 16:33:54, 16:33...</td>\n",
       "      <td>[1464939437, 1464939434, 1464939434, 146493943...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16734_5b37d580c76a8c8c245cad3418349acb</th>\n",
       "      <td>[out, in, 1f]</td>\n",
       "      <td>[1445856050, 1445856052, 1445856052]</td>\n",
       "      <td>[662, 527, 527]</td>\n",
       "      <td>[19:40:50, 19:40:52, 19:40:52]</td>\n",
       "      <td>[1445856712, 1445856579, 1445856579]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16736_70968e4fb8894b74997f6f4e89b32bee</th>\n",
       "      <td>[out, in, 1f]</td>\n",
       "      <td>[1446031391, 1446031392, 1446031392]</td>\n",
       "      <td>[152, 144, 144]</td>\n",
       "      <td>[20:23:11, 20:23:12, 20:23:12]</td>\n",
       "      <td>[1446031543, 1446031536, 1446031536]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847_e0b87d079ff087efd100c423d88d0fbd</th>\n",
       "      <td>[out, in, 1f]</td>\n",
       "      <td>[1455604283, 1455604408, 1455604408]</td>\n",
       "      <td>[369, 94, 94]</td>\n",
       "      <td>[15:31:23, 15:33:28, 15:33:28]</td>\n",
       "      <td>[1455604652, 1455604502, 1455604502]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    traj  \\\n",
       "16767_25e9517c47319ab64486403f94348dd6       [out, in, 2f, 2f-inner, 1f]   \n",
       "16955_53f0a6276486cc80405cf534d913fcbb  [out, in, 1f, 1f-right, 1f-left]   \n",
       "16734_5b37d580c76a8c8c245cad3418349acb                     [out, in, 1f]   \n",
       "16736_70968e4fb8894b74997f6f4e89b32bee                     [out, in, 1f]   \n",
       "16847_e0b87d079ff087efd100c423d88d0fbd                     [out, in, 1f]   \n",
       "\n",
       "                                                                                       ts  \\\n",
       "16767_25e9517c47319ab64486403f94348dd6  [1448711070, 1448711259, 1448711286, 144871128...   \n",
       "16955_53f0a6276486cc80405cf534d913fcbb  [1464939171, 1464939171, 1464939171, 146493923...   \n",
       "16734_5b37d580c76a8c8c245cad3418349acb               [1445856050, 1445856052, 1445856052]   \n",
       "16736_70968e4fb8894b74997f6f4e89b32bee               [1446031391, 1446031392, 1446031392]   \n",
       "16847_e0b87d079ff087efd100c423d88d0fbd               [1455604283, 1455604408, 1455604408]   \n",
       "\n",
       "                                                       dwell_time  \\\n",
       "16767_25e9517c47319ab64486403f94348dd6     [314, 125, 98, 98, 65]   \n",
       "16955_53f0a6276486cc80405cf534d913fcbb  [266, 263, 263, 198, 156]   \n",
       "16734_5b37d580c76a8c8c245cad3418349acb            [662, 527, 527]   \n",
       "16736_70968e4fb8894b74997f6f4e89b32bee            [152, 144, 144]   \n",
       "16847_e0b87d079ff087efd100c423d88d0fbd              [369, 94, 94]   \n",
       "\n",
       "                                                                               time_start  \\\n",
       "16767_25e9517c47319ab64486403f94348dd6  [20:44:30, 20:47:39, 20:48:06, 20:48:06, 20:48...   \n",
       "16955_53f0a6276486cc80405cf534d913fcbb  [16:32:51, 16:32:51, 16:32:51, 16:33:54, 16:33...   \n",
       "16734_5b37d580c76a8c8c245cad3418349acb                     [19:40:50, 19:40:52, 19:40:52]   \n",
       "16736_70968e4fb8894b74997f6f4e89b32bee                     [20:23:11, 20:23:12, 20:23:12]   \n",
       "16847_e0b87d079ff087efd100c423d88d0fbd                     [15:31:23, 15:33:28, 15:33:28]   \n",
       "\n",
       "                                                                                   ts_end  \\\n",
       "16767_25e9517c47319ab64486403f94348dd6  [1448711384, 1448711384, 1448711384, 144871138...   \n",
       "16955_53f0a6276486cc80405cf534d913fcbb  [1464939437, 1464939434, 1464939434, 146493943...   \n",
       "16734_5b37d580c76a8c8c245cad3418349acb               [1445856712, 1445856579, 1445856579]   \n",
       "16736_70968e4fb8894b74997f6f4e89b32bee               [1446031543, 1446031536, 1446031536]   \n",
       "16847_e0b87d079ff087efd100c423d88d0fbd               [1455604652, 1455604502, 1455604502]   \n",
       "\n",
       "                                        revisit_intention  \n",
       "16767_25e9517c47319ab64486403f94348dd6                0.0  \n",
       "16955_53f0a6276486cc80405cf534d913fcbb                0.0  \n",
       "16734_5b37d580c76a8c8c245cad3418349acb                0.0  \n",
       "16736_70968e4fb8894b74997f6f4e89b32bee                1.0  \n",
       "16847_e0b87d079ff087efd100c423d88d0fbd                0.0  "
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10, 9)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate dummy training data\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, nb_classes))\n",
    "\n",
    "# generate dummy validation data\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, nb_classes))\n",
    "\n",
    "\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(10)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(0)\n",
    "a = np.append(a, 2)\n",
    "a = np.append(a, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 4.,  4.,  4.]), array([ 8.,  8.,  8.])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  4.,  4.],\n",
       "       [ 8.,  8.,  8.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "da = embedding(df2.ix[0])\n",
    "db = embedding(df2.ix[1])\n",
    "x.append(da)\n",
    "x.append(db)\n",
    "print(x)\n",
    "np.stack(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.head(1000)\n",
    "embeddedvector = df3.apply(lambda x: embedding(x), axis=1)\n",
    "np.asarray(embeddedvector).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab = np.zeros((10, 1, 3))\n",
    "ab[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = df2.head(1000)\n",
    "np.asarray(pd.get_dummies(dff['revisit_intention']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal.outer(2, np.arange(4)).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2])\n",
    "b = np.array([3, 4])\n",
    "c = 5\n",
    "aa = np.append(a,b)\n",
    "np.append(aa, c)\n",
    "\n",
    "twod_result = np.zeros((10, 36)).shape[1]\n",
    "print(twod_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "areavecdict = {}\n",
    "areavecdict['out'] =      np.array([0, 0, 0, 0, 0, 0, 0])\n",
    "areavecdict['in'] =       np.array([1, 0, 0, 0, 0, 0, 0])\n",
    "areavecdict['1f'] =       np.array([1, 1, 0, 0, 0, 0, 0])\n",
    "areavecdict['2f'] =       np.array([1, 0, 1, 0, 0, 0, 0])\n",
    "areavecdict['3f'] =       np.array([1, 0, 0, 1, 0, 0, 0])\n",
    "areavecdict['1f-inner'] = np.array([1, 1, 0, 0, 1, 0, 0])\n",
    "areavecdict['1f-left'] =  np.array([1, 1, 0, 0, 0, 1, 0])\n",
    "areavecdict['1f-right'] = np.array([1, 1, 0, 0, 0, 0, 1])\n",
    "areavecdict['2f-inner'] = np.array([1, 0, 1, 0, 1, 0, 0])\n",
    "areavecdict['2f-left'] =  np.array([1, 0, 1, 0, 0, 1, 0])\n",
    "areavecdict['2f-right'] = np.array([1, 0, 1, 0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztzt = np.zeros(5)\n",
    "for i in range(2, 5):\n",
    "    ztzt[i] = 1\n",
    "ztzt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Future work의 한계를 극복하고 탑티어 컨퍼런스를 만들고 그거슬 저널 확장한후에 프로포절을 하고 또 하나의 state-of-the-art를 만들어서 탑티어 컨퍼런스에서 발표해야 우리 교수님 기준 디펜스가 가능함\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "def getuniqueareas(trajseries):\n",
    "    aggregated_traj = list(itertools.chain.from_iterable(trajseries))\n",
    "    uniqueareas = sorted(list(set(aggregated_traj)))\n",
    "    return uniqueareas\n",
    "\n",
    "        \n",
    "areas = getuniqueareas(df3.traj)\n",
    "\n",
    "\n",
    "# print(str(df3.traj).value_count())\n",
    "def embedding(x, areas):\n",
    "    datalen = len(x.traj)\n",
    "    twod_result = np.zeros((10, 1447)) \n",
    "    for idx in range(datalen):\n",
    "#         print(idx)\n",
    "#         print(twod_result.shape[0])\n",
    "        if(idx < twod_result.shape[0]):\n",
    "            \n",
    "            area_name = x.traj[idx]\n",
    "            area_num = areas.index(area_name)\n",
    "            area_vec = areavecdict.get(area_name)\n",
    "            \n",
    "#             area_vec = np.equal.outer(area_num, np.arange(len(areas))).astype(np.float)\n",
    "#             print(area_num)\n",
    "#             print(area_vec)\n",
    "\n",
    "\n",
    "            starttime_name = x.ts[idx]\n",
    "#             starttime_num = int(starttime_name[:starttime_name.index( ':')]) \n",
    "            starttime_num = int(starttime_name)\n",
    "            snum_refine = (starttime_num /60 % 1440 + 540) % 1440\n",
    "            \n",
    "    \n",
    "#             starttime_name = x.time_start[idx]\n",
    "\n",
    "#             starttime_vec = np.equal.outer(starttime_num, np.arange(24)).astype(np.float)\n",
    "            \n",
    "    #         print(starttime_name)\n",
    "    #         print(starttime_num)\n",
    "    #         print(starttime_vec)\n",
    "    \n",
    "            endtime_name = x.ts_end[idx]\n",
    "            endtime_num = int(endtime_name)\n",
    "            enum_refine = (endtime_num /60 % 1440 + 540) % 1440\n",
    "            \n",
    "            sr = math.floor(snum_refine)\n",
    "            er = math.ceil(enum_refine)\n",
    "            \n",
    "            dt_vec = np.zeros(1440)\n",
    "            for i in range(sr, er):\n",
    "                dt_vec[i] = 1\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "#             dwelltime_num = int(x.dwell_time[idx])\n",
    "#             print('d', dwelltime_num % 60)\n",
    "\n",
    "            total_vec = np.append(area_vec, dt_vec)\n",
    "#             total_vec = np.append(total_vec, dt_vec)\n",
    "#             print(total_vec)\n",
    "            \n",
    "            twod_result[idx, :] = total_vec\n",
    "    \n",
    "    return twod_result\n",
    "\n",
    "\n",
    "\n",
    "def dataGenerator():\n",
    "    df3 = df2   ## .head(1000)\n",
    "    areas = getuniqueareas(df3.traj)\n",
    "    length = df3.shape[0]\n",
    "    steps = 10\n",
    "    dim = 1447\n",
    "    x = np.zeros((length, steps, dim))\n",
    "    idx = 0\n",
    "    \n",
    "    for row in df3.itertuples():  \n",
    "#         print(len(row.traj))\n",
    "        rowrst = embedding(row, areas)\n",
    "        x[idx, :, :] = rowrst\n",
    "        idx += 1\n",
    "    \n",
    "    x_train = x[:7500, :, :]\n",
    "    x_val = x[7500:,:, :]\n",
    "    \n",
    "    y = np.asarray(pd.get_dummies(df3['revisit_intention']))\n",
    "    y_train = y[:7500, :]\n",
    "    y_val = y[7500:, :]\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val  \n",
    "    \n",
    "\n",
    "    \n",
    "# print(df3.ix[39])\n",
    "# print('-----')\n",
    "# print(embedding(df3.ix[1], areas))\n",
    "\n",
    "x_train, x_val, y_train, y_val = dataGenerator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def embedding(x):\n",
    "    \n",
    "    \n",
    "    \n",
    "#     a = np.zeros(0)\n",
    "#     b = len(x.traj)\n",
    "#     c = len(x.time_start)\n",
    "#     d = len(x.dwell_time)\n",
    "#     e = x.revisit_intention\n",
    "#     a = np.append(a, b)\n",
    "#     a = np.append(a, c)\n",
    "#     a = np.append(a, d)\n",
    "#     a = np.append(a, e)\n",
    "#     return a\n",
    "\n",
    "# def dataGenerator():\n",
    "#     df3 = df2.head(1000)\n",
    "    \n",
    "#     length = df3.shape[0]\n",
    "#     steps = 1\n",
    "#     dim = 3\n",
    "#     x = np.zeros((length, steps, dim))\n",
    "#     idx = 0\n",
    "#     for row in df3.itertuples():  \n",
    "#         b = len(row.traj)\n",
    "#         c = len(row.time_start)\n",
    "#         d = len(row.dwell_time)\n",
    "#         rowrst = np.asarray([b, c, d])\n",
    "#         x[idx, 0] = rowrst\n",
    "#         idx += 1\n",
    "    \n",
    "#     x_train = x[:900, :, :]\n",
    "#     x_val = x[900:,:, :]\n",
    "    \n",
    "#     y = np.asarray(pd.get_dummies(dff['revisit_intention']))\n",
    "#     y_train = y[:900, :]\n",
    "#     y_val = y[900:, :]\n",
    "    \n",
    "#     return x_train, x_val, y_train, y_val     \n",
    "\n",
    "# #     df3['result'] = df3.apply(lambda x: embedding(x), axis=1)\n",
    "# #     result = np.asarray(df3['result'])\n",
    "# #     return result\n",
    "    \n",
    "# x_train, x_val, y_train, y_val = dataGenerator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1386 samples\n",
      "Epoch 1/20\n",
      "7500/7500 [==============================] - 17s - loss: 0.6811 - acc: 0.5537 - val_loss: 0.6831 - val_acc: 0.5455\n",
      "Epoch 2/20\n",
      "7500/7500 [==============================] - 12s - loss: 0.6694 - acc: 0.5799 - val_loss: 0.6797 - val_acc: 0.5693\n",
      "Epoch 3/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.6613 - acc: 0.5947 - val_loss: 0.6795 - val_acc: 0.5649\n",
      "Epoch 4/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.6520 - acc: 0.6115 - val_loss: 0.7058 - val_acc: 0.5527\n",
      "Epoch 5/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.6422 - acc: 0.6251 - val_loss: 0.7077 - val_acc: 0.5433\n",
      "Epoch 6/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.6316 - acc: 0.6391 - val_loss: 0.7061 - val_acc: 0.5527\n",
      "Epoch 7/20\n",
      "7500/7500 [==============================] - 12s - loss: 0.6190 - acc: 0.6497 - val_loss: 0.7042 - val_acc: 0.5519\n",
      "Epoch 8/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.6081 - acc: 0.6635 - val_loss: 0.7252 - val_acc: 0.5512\n",
      "Epoch 9/20\n",
      "7500/7500 [==============================] - 12s - loss: 0.5935 - acc: 0.6811 - val_loss: 0.7659 - val_acc: 0.5397\n",
      "Epoch 10/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.5777 - acc: 0.6892 - val_loss: 0.7658 - val_acc: 0.5310\n",
      "Epoch 11/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.5627 - acc: 0.7059 - val_loss: 0.7671 - val_acc: 0.5274\n",
      "Epoch 12/20\n",
      "7500/7500 [==============================] - 12s - loss: 0.5450 - acc: 0.7124 - val_loss: 0.7785 - val_acc: 0.5491\n",
      "Epoch 13/20\n",
      "7500/7500 [==============================] - 12s - loss: 0.5290 - acc: 0.7271 - val_loss: 0.8486 - val_acc: 0.5469\n",
      "Epoch 14/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.5110 - acc: 0.7399 - val_loss: 0.8895 - val_acc: 0.5289\n",
      "Epoch 15/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.4964 - acc: 0.7520 - val_loss: 0.8950 - val_acc: 0.5260\n",
      "Epoch 16/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.4768 - acc: 0.7616 - val_loss: 0.9326 - val_acc: 0.5332\n",
      "Epoch 17/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.4593 - acc: 0.7768 - val_loss: 0.9967 - val_acc: 0.5310\n",
      "Epoch 18/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.4372 - acc: 0.7945 - val_loss: 0.9842 - val_acc: 0.5325\n",
      "Epoch 19/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.4235 - acc: 0.7961 - val_loss: 0.9781 - val_acc: 0.5238\n",
      "Epoch 20/20\n",
      "7500/7500 [==============================] - 11s - loss: 0.4021 - acc: 0.8155 - val_loss: 1.0897 - val_acc: 0.5202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208d25ba8>"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = x_val.shape[2]\n",
    "timesteps = x_val.shape[1]\n",
    "nb_classes = 2\n",
    "\n",
    "# def modelGenerator():\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# # generate dummy training data\n",
    "# x_train = np.random.random((1000, timesteps, data_dim))\n",
    "# y_train = np.random.random((1000, nb_classes))\n",
    "\n",
    "# # generate dummy validation data\n",
    "# x_val = np.random.random((100, timesteps, data_dim))\n",
    "# y_val = np.random.random((100, nb_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, nb_epoch=20,\n",
    "          validation_data=(x_val, y_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def LSTMtrial(x_train, y_train):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_dim = 16\n",
    "# timesteps = 1\n",
    "# nb_classes = 10\n",
    "\n",
    "# # expected input data shape: (batch_size, timesteps, data_dim)\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(32, return_sequences=True,\n",
    "#                input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "# model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "# model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # generate dummy training data\n",
    "# x_train = np.random.random((1000, timesteps, data_dim))\n",
    "# y_train = np.random.random((1000, nb_classes))\n",
    "\n",
    "# # generate dummy validation data\n",
    "# x_val = np.random.random((100, timesteps, data_dim))\n",
    "# y_val = np.random.random((100, nb_classes))\n",
    "\n",
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=64, nb_epoch=20,\n",
    "#           validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stratified K-Fold  (https://github.com/fchollet/keras/issues/1711)\n",
    "### http://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "def load_data():\n",
    "    # load your data using this function\n",
    "\n",
    "def create model():\n",
    "    # create your model using this function\n",
    "\n",
    "def train_and_evaluate__model(model, data[train], labels[train], data[test], labels[test)):\n",
    "    model.fit...\n",
    "    # fit and evaluate here.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_folds = 10\n",
    "    data, labels, header_info = load_data()\n",
    "    skf = StratifiedKFold(labels, n_folds=n_folds, shuffle=True)\n",
    "\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "            print \"Running Fold\", i+1, \"/\", n_folds\n",
    "            model = None # Clearing the NN.\n",
    "            model = create_model()\n",
    "            train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other examples (Not directly related to our project from here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 1s - loss: 11.5468 - acc: 0.0980 - val_loss: 12.0041 - val_acc: 0.1200\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5459 - acc: 0.0940 - val_loss: 12.0037 - val_acc: 0.1700\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5457 - acc: 0.1060 - val_loss: 12.0038 - val_acc: 0.1600\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5456 - acc: 0.1090 - val_loss: 12.0037 - val_acc: 0.1700\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5453 - acc: 0.1110 - val_loss: 12.0039 - val_acc: 0.1600\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5451 - acc: 0.1030 - val_loss: 12.0039 - val_acc: 0.1700\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5449 - acc: 0.1050 - val_loss: 12.0037 - val_acc: 0.1600\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5446 - acc: 0.1030 - val_loss: 12.0033 - val_acc: 0.1600\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5443 - acc: 0.1140 - val_loss: 12.0034 - val_acc: 0.1800\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5440 - acc: 0.1030 - val_loss: 12.0034 - val_acc: 0.1700\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5438 - acc: 0.1020 - val_loss: 12.0032 - val_acc: 0.1800\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5433 - acc: 0.1110 - val_loss: 12.0035 - val_acc: 0.1300\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5429 - acc: 0.1140 - val_loss: 12.0036 - val_acc: 0.1600\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5425 - acc: 0.1230 - val_loss: 12.0033 - val_acc: 0.1600\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5421 - acc: 0.1150 - val_loss: 12.0035 - val_acc: 0.1600\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5417 - acc: 0.1230 - val_loss: 12.0031 - val_acc: 0.1500\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5413 - acc: 0.1320 - val_loss: 12.0032 - val_acc: 0.1400\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5407 - acc: 0.1280 - val_loss: 12.0042 - val_acc: 0.1300\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5405 - acc: 0.1230 - val_loss: 12.0035 - val_acc: 0.1400\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s - loss: 11.5400 - acc: 0.1310 - val_loss: 12.0036 - val_acc: 0.1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1256c0898>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 1\n",
    "nb_classes = 10\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# generate dummy training data\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, nb_classes))\n",
    "\n",
    "# generate dummy validation data\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, nb_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, nb_epoch=20,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8, 16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "'''Compare LSTM implementations on the IMDB sentiment classification task.\n",
    "consume_less='cpu' preprocesses input to the LSTM which typically results in\n",
    "faster computations at the expense of increased peak memory usage as the\n",
    "preprocessed input must be kept in memory.\n",
    "consume_less='mem' does away with the preprocessing, meaning that it might take\n",
    "a little longer, but should require less peak memory.\n",
    "consume_less='gpu' concatenates the input, output and forget gate's weights\n",
    "into one, large matrix, resulting in faster computation time as the GPU can\n",
    "utilize more cores, at the expense of reduced regularization because the same\n",
    "dropout is shared across the gates.\n",
    "Note that the relative performance of the different `consume_less` modes\n",
    "can vary depending on your device, your model and the size of your data.\n",
    "'''\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, LSTM\n",
    "from keras.datasets import imdb\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "max_features = 20000\n",
    "max_length = 80\n",
    "embedding_dim = 256\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "modes = ['cpu', 'mem', 'gpu']\n",
    "\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
    "X_train = sequence.pad_sequences(X_train, max_length)\n",
    "X_test = sequence.pad_sequences(X_test, max_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mode: consume_less=\"cpu\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sundong/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 602s - loss: 0.5455 - acc: 0.7157 - val_loss: 0.4051 - val_acc: 0.8210\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 635s - loss: 0.3822 - acc: 0.8353 - val_loss: 0.3721 - val_acc: 0.8371\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 719s - loss: 0.3192 - acc: 0.8673 - val_loss: 0.3989 - val_acc: 0.8286\n",
      "Epoch 4/10\n",
      "23296/25000 [==========================>...] - ETA: 29s - loss: 0.2750 - acc: 0.8865"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-431-9d759df588ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                         \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                         validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0maverage_time_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sundong/anaconda/envs/py35/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/sundong/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sundong/anaconda/envs/py35/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sundong/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sundong/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sundong/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sundong/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/sundong/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sundong/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compile and train different models while meauring performance.\n",
    "results = []\n",
    "for mode in modes:\n",
    "    print('Testing mode: consume_less=\"{}\"'.format(mode))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embedding_dim, input_length=max_length, dropout=0.2))\n",
    "    model.add(LSTM(embedding_dim, dropout_W=0.2, dropout_U=0.2, consume_less=mode))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        nb_epoch=epochs,\n",
    "                        validation_data=(X_test, y_test))\n",
    "    average_time_per_epoch = (time.time() - start_time) / epochs\n",
    "\n",
    "    results.append((history, average_time_per_epoch))\n",
    "\n",
    "# Compare models' accuracy, loss and elapsed time per epoch.\n",
    "plt.style.use('ggplot')\n",
    "ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.set_ylabel('Validation Accuracy')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax2 = plt.subplot2grid((2, 2), (1, 0))\n",
    "ax2.set_title('Loss')\n",
    "ax2.set_ylabel('Validation Loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax3 = plt.subplot2grid((2, 2), (0, 1), rowspan=2)\n",
    "ax3.set_title('Time')\n",
    "ax3.set_ylabel('Seconds')\n",
    "for mode, result in zip(modes, results):\n",
    "    ax1.plot(result[0].epoch, result[0].history['val_acc'], label=mode)\n",
    "    ax2.plot(result[0].epoch, result[0].history['val_loss'], label=mode)\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax3.bar(np.arange(len(results)), [x[1] for x in results],\n",
    "        tick_label=modes, align='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Data\n",
      "Input shape: (50000, 1, 1)\n",
      "Output shape\n",
      "(50000, 1)\n",
      "Creating Model\n",
      "Training\n",
      "Epoch 0 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 21s - loss: 351.3465    \n",
      "Epoch 1 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 23s - loss: 171.3398    \n",
      "Epoch 2 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 26s - loss: 93.2602    \n",
      "Epoch 3 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 23s - loss: 60.4686    \n",
      "Epoch 4 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 28s - loss: 46.5839    \n",
      "Epoch 5 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s - loss: 35.5704    \n",
      "Epoch 6 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 18s - loss: 21.8389    \n",
      "Epoch 7 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 16s - loss: 16.1920    \n",
      "Epoch 8 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 16s - loss: 13.3390    \n",
      "Epoch 9 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 16s - loss: 10.5758    \n",
      "Epoch 10 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 17s - loss: 8.8063    \n",
      "Epoch 11 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s - loss: 7.3773    \n",
      "Epoch 12 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 27s - loss: 6.3475    \n",
      "Epoch 13 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 26s - loss: 5.6289    \n",
      "Epoch 14 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 29s - loss: 6.1465    \n",
      "Epoch 15 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s - loss: 5.6031    \n",
      "Epoch 16 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s - loss: 4.9063    \n",
      "Epoch 17 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s - loss: 5.5068    \n",
      "Epoch 18 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 22s - loss: 4.4726    \n",
      "Epoch 19 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 23s - loss: 5.0388    \n",
      "Epoch 20 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s - loss: 4.6618    \n",
      "Epoch 21 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s - loss: 3.8356    \n",
      "Epoch 22 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 18s - loss: 4.0736    \n",
      "Epoch 23 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 15s - loss: 3.9417    \n",
      "Epoch 24 / 25\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 13s - loss: 7.7293    \n",
      "Predicting\n",
      "Plotting Results\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXeYVNX5x78vu0tfeq9SBBFRsGDXtSHG2JJIsCVqNDEa\nNRaixhjBFJMYY4nRGBOJvScRYwMFjJr4ExuCdOltKQvLLixbz++P7xzvufeeO7sLDDsL7+d59pnZ\ne+beOffOzPnet5z3iDEGiqIoilIbTRq6A4qiKErjQAVDURRFqRMqGIqiKEqdUMFQFEVR6oQKhqIo\nilInVDAURVGUOqGCoShZiIh8V0Tebeh+KIqLCoayxyAiS0Vkm4hsEZGS1OP9DdSXaSJy6U4eRidJ\nKVlFbkN3QFF2IQbA6caYaQ3dEUXZE1ELQ9nTkNgGkQdF5EXn/9+KyJTU8+NFZIWI3CIi60VksYic\n77y2qYj8XkSWicia1LGaOe1nicinIlIsIgtFZJSI/BLAsQAecK0cEdlPRCaLyEYRmSsi5zrH6SAi\nk1LH+QDAgIxcHUXZCdTCUPYGbgDwqYh8B8ASAJcAOMhp7wagA4AeAI4E8JqIzDDGLATwWwD9ABwI\noArA0wB+DuBWERkJ4DEA3zDGTBWR7gDyjTGTReRoAE8YYx4FABFpCWAygJ8BODV1vLdEZJYxZh6A\nBwFsA9AVFIs3ASzO2BVRlB1ALQxlT+NfIlIkIptSj98zxpQB+A6AewA8DuBHxpg1zj4GwG3GmEpj\nzH8AvApgTKrtcgDXGWOKjTFbAfwGwHmptksB/M0YMxUAjDFrjDELEvr1dQBLjDGPGzITwEsAzhWR\nJgC+kerDdmPMF6AQKUpWoRaGsqdxli+GYYz5UEQWA+gM4IVI8yZjzHbn/2UAeohIZwAtAXws8pWn\nqwkCt1dvUFzqQl8AR4hIUep/AZADClhn8Le4MtKHY+t4bEXZLaiFoexpxGIYACAiVwFoCmA1gJsi\nze1FpIXzf5/U6zaAbqKhxpgOqb92xpi2qdetQHKsIZrhtALAdOc47Y0xbYwxPwKwHkAlKEBuHxQl\nq1DBUPZ4RGQQgF8AuAB0Tf1ERA50XwJggojkicixAE4H8Lxh7f9HANybsjYgIj1FZFRqv78BuERE\nThDSQ0QGp9oKAfR33uPfAAaJyIUikpt6r0NFZLAxpgbAPwCMF5EWIrI/gO9m5GIoyk6ggqHsabwS\nmYfxEuj2udMYM9sYswjATwE8ISJ5qX3WANgEWhVPAPhBKuAN0BpZBOADEdkMBq4HAYAxZgYYQL8X\nQDGA6Qgsg/vA+MRGEbnXGFMKYBSAsan3WQ3GQ2zG1dUA8lN9eTT1pyhZheyKBZRE5G9gUK/QGHNg\nalt7AM+BvtulAMYYY4pTbbeAAcMqANcaYybvdCcUZQcQkePBbCZ1ASlKLewqC2MimCrocjOAt4wx\ngwFMBXALAKTM7TEAhgA4DcCD4kQUFUVRlOxklwiGMeY90KR3OQtBauBjAM5OPT8TwLPGmCpjzFIA\nCwGM3BX9UBRFUTJHJmMYXYwxhQBgjFkLoEtqe08wY8SyKrVNUXY7xph31B2lKHVjdwa9tZCaoihK\nIyaTE/cKRaSrMaZQRLoBWJfavgrhfPNeqW0xRERFRlEUZQcwxuzy2PCutDAE4UlTkwBcnHr+XQAv\nO9vHpoq69QMwEMCHSQc1xuifMbj99tsbvA/Z8qfXQq+FXov0f5lil1gYIvI0gAIAHUVkOYDbwRzz\nF1JrAixDqjaPMWaOiDwPYA44u/VKk8kzVBRFUXYJu0QwjDHnJzSdnPD6OwHcuaPvV10N5OTs6N6K\noijKjtDoZnrPng3k5gI1NQ3dk91LQUFBQ3cha9BrEaDXIkCvRebZJTO9M4WIxLxVL70EfOtbwNq1\nQNeuDdQxRVGULEZEYLI86L1bKCzk4+rVDdsPRVGUvY1GKxibNzdsPxRFUfY2Gp1gbEoVINmyJd72\n9tvAk0/u3v4oiqLsLTQ6wdieWhfNJxjXXQdcdNHu7Y+iKMreQqMTjIoKoFkzoKQk3lZZufv7oyiK\nsrfQ6ASjvBzo3NlvYahgKIqiZI5GKRgdOwKlpfG2igo+VlfH226/HZg5M7N9UxRF2ZNplILRrl0Q\ny3CxguGzPu64A5g4MbN9UxRF2ZPJesGIWgvl5UDbtkBZWfy127cDrVsDxcXh7fa15eWZ6aOiKMre\nQNYLRtSSSGdhlJdz9ndUMFaliqcXFfnfY+PGne+noijKnk7WC0bUkrCCEd1uDEWkQwdg27Zwm3VR\nbYouIgtgyRKgUycVDUVRlNrIesGwcQmLdUlFLYyKCiAvjy6pqGBs3w6I+GeHz5vHx7lzd12fFUVR\n9kQapWD4LIzycqB5c6BFi3hbWRnQvbtfMGxNqrVrd12fFUVR9kQapWD4gt7bt3NCX8uWfgujW7f0\ngrFhQ7zthReAs8/e8b4riqLsSTRawYi6pLZvT29hdOwYFxKAsYsWLfyC8cwzwMsvx7criqLsjeyS\nFffSISJLARQDqAFQaYwZKSLtATwHoC+ApQDGGGOKffvX1cKwLqkkC8MKhjGMZ1jKyoBevfwZVFVV\nwbGbNavjCSuKouyh7A4LowZAgTFmhDFmZGrbzQDeMsYMBjAVwC1JOyfFMHwWRrNmyRZGq1ZA06bx\nuRhlZSw14ps5btNx16+Pt516KnDPPUm9VhRF2fPYHYIhnvc5C8BjqeePAUiMFNQnhpHOwkhq27Yt\nWTCKioA2bfyCMXky8O9/J/VaURRlz2N3CIYBMEVEZojIZaltXY0xhQBgjFkLoEvSzq5FUFNDN1E6\nl1SShdGiBQVj69Z4W5cufsHYtg3o2zce37DWja9mFQD85z9735rjiqLs+WQ8hgHgaGPMGhHpDGCy\niMwHRcQlcWHxiRPH4/33+fyoowrQtGkBmjWLWx5ullR0Ep61MFq1ilsY1iW1cGH8vbdu5czxaCn1\nFSv4aFf/c1m+HDj+eOC//wWOPDLprBRFUXYd06dPx/Tp0zP+PhkXDGPMmtTjehH5F4CRAApFpKsx\nplBEugFYl7T/ueeOxznn8HlxMUUhSTDSWRj5+X6XVJKFYQxf6xOM4mKgTx+/YMyfz8cvvlDBUBRl\n91BQUICCgoKv/p8wYUJG3iejLikRaSkirVPPWwEYBWAWgEkALk697LsAEpNXXWGw2Uo2eG1MuC1J\nMNLFMJKC3uXlfJ+2beOCsXUr0LMnS46YiG20eDEfbcDc5fXXgf32SzpTRVGU7CbTFkZXAP8UEZN6\nr6eMMZNF5CMAz4vIpQCWARiTdACfYOTkMDW2uhrITZ2BdUk1a+bPhGrRItkl5bMwtm2jwOTn+wWj\nbVuKUGkpX2NZt461qXyC8fbbtEC2bGEwXVEUpTGRUcEwxiwBMNyzvQjAyXU5hk8wgMAt5QpG8+Z+\nwahLllRUFGoTjFatKBrFxWHBKCkB+vXzFzNcsoSPy5YBw4aF2/70Jx7vwguTr4WiKEpD0qhmeruC\nEZ1TYV1S6SyMpCypDh3ibixXMKILMpWWUjDatImXUi8tBXr39lfGXbaM77V8ebztRz8Cfvzj+HZF\nUZRsoVELhtuWziWVzvooK+NEwIqKcJrstm2BKNRmYbiUlnLmuK9uVXExMGhQPE3XpuDm5MT3qa4G\nzjwzCKYriqI0FFkvGFErIuqSstTFJdW8eXiGuF1Do2VLtrn7bd3K7a1bx+MbrmBErY+SEloYPsHY\nsgXYZ5+4u2r1asY9Nm2Kz+2YPx945ZXkSYI630NRlN1F1gvGrnRJRUXBxkBycuLZVdYl1bJl3F1l\nBaO+LqmSEgpGtG7VunXMumrbNt62YAEf7bodLtOmse+69KyiKLuDRi0YO+KSci2MbdsoFECyYLRo\nEQ+Ub91Ky6NVq3hMpKQkSLl17/4rK9nfXr3iFsaWLRSLTp3iZUgWLWIq7rJl8Wvz1lt8nD073jZn\nDvDZZ/HtiqIoO0qjFYz6uKRcC8MVDLsdSG9hRAXDBr19abqlpYyJtGwZdmWVlDCA3rFj3IooLqZg\ndO4cF4wNG5hRlTRJsEkTikOUMWOAo46Kb1cURdlRGp1gNG3K5/VxSSXFMOoiGL6JgNYl5bMwSktp\nfbRuHW6zgtG+fdxdlU4wNm8GBg/2C8aiRcCJJ/rnfCxbxn5HZ8RXV7M+1j/+Ed9HURQlHY1OMHbE\nJZUUw3AFo3nzulsY6QSjpCQQDNfCsJP1fPM6rGB07Bh3V23eHGRWRQPiGzYAw4cHqwZarCD17h0X\nk/nzmdY7aRJiFBUxtbeyMt6mKIrSaAVjR7KkojGMsjIKAkDhiMY3agt6J7mr8vPZ7nNJJQlGmzb+\nNN1Nm2h5+ALiRUXAAQfERWHpUmDAAFoS0Tkfc+ZwudpZsxDjqaeA++4DfDXM5s/nTHVFUfZeGq1g\n7GiWVH2C3q1a1S/oXVHBQHfTpjtmYfjSdDdvZkwk6soqK6PF0b8/sHZteJ8NGygyvXsHlXUt8+YB\np53mD6LPnMn+ffhhvO3qq4GTT/an8b73XrwPiqLseWS9YETTYOvrkrJzLeobw7DzMOrjkrLxC5G4\nYJSUUDB8EwGtYPjSdK1gtGsXntuxaRNnjXfsGI+JbNjA7T16xN1Va9bQjbVtW7wfs2cD55wDfPll\neLsxFJNmzYC5c8NtZWXAsccCN9yAGDU1wPPPB0vdKorSuGlUglEXl1RuLgcq6++vrGQmUW5uXEzq\nEvRu2pTHcgc9myUVLTXiFiKMBr23bAlcUtEqtzatNskl1b49/3yC0aFDPO6xYQNTdDt1is8qX7eO\nJdt91sfy5bQiooKxdi2vwamnxueDfPophe699xDj5ZeBb38bePHFeNv8+cDf/x7frihK9pL1guEG\nYOvikhIJC4MVEiC9hZEU9BbxWx++tFprYQDJLqm8PIqX248kl5QxFIm2bWlhuJZEURHFon17PncF\naONGikXnznHBWL+e27t2pXhYqqvZNnIkYyAuy5bR9TV4cDCR0PLRR8DYsXyfqMUybRrjKFOmIMYt\ntwCXXAKsXBlvu/NOxlN8RMvJK4qy+8h6wahvlhQQFoyoKKRzSfmC3kDcLZXkkrKBbcDvkrJt0ThG\nkkuqrIwzuZs3j1sYVjCsG859L+uSSrIwunSJC8bGjexDnz60KNyBedUqTkbs3z+ouGtZsoRZXIMG\nxa2PGTOAK66IB9irq4GpU7ky4dSp4bYNG4Cf/pTZWr61Rpo3B159FTG2bAHeeSe+XVGUXUejFYwk\nl5Rtq6uF4WZJ+SyMaJsx4SwpXwwDSLYwgHgF3KQsqc2bKRRAPIZhBQOITwa0LinfvA4rGF26hOd2\nrF3L7KkWLfjnvtfq1YyH9OwZz8hasYIis+++weJRlsWLWThxzpxwsHz5cl6D004DPv88vM/UqcAZ\nZ7APUdfY009zv4cfRoybbgIKCoBPPom33Xkn/3wsWhSfq6Ioip9GKxhJLikg2cKIxjDqUhoECFsY\n5eV0KeXlxV1Sdg4GkN7CiAa+k1xSmzZRKIBklxQQj2Ns3Oi3MKqqKAQdO8YtjMJCCgbAxzVrgrbV\nqykWPsFYvpzxkN69wym8W7fyXPbbj9fJzaKaP5/urQMOiJc1mTULGDECOPhgxkdcpk8H7r4bePfd\nsPVRUwO88AJw0UXxeMmaNcCECcDtt8cnP37yCYVu3DjE+PBD4FvfigsuQJGMBv8VZW+gwQRDREaL\nyDwRWSAiNyW9LinoXVeXVF1jGElptUB4LoYNeAP+LKl0QW/XwqiLS8pmSAHJLimAj3WxMDZu5HFy\ncmhhuIJhLQyAj+4Av2pVsoWxfDktjGgQfelSxi+aNGHBRTcuMn8+XVhDh8YFY948YMgQZnJFBWPW\nLAbl8/PD1seXX/J6X3QR8N//hvd5803grLP498Yb4ba//Q246irgiSfiVsa4cRSNP/whvL2iAjju\nOIqaK6oAP4ODDwZ+9SvEWLOGohV1EQL8zKPWlKJkIw0iGCLSBMADAE4FMBTAeSLiXe16V7ik6hrD\nSOeSspaEdUcB6V1SSRP3gLBgVFfz2Pn5gUvK3j1HXVJRC8O2+SyMTp14vK1bg8SB9espFECySwoA\nuncPC4Z1SXXuzP7Za1tezj75sq6WLOHKgwCFw533sWABLYw+fbi/K55z59IqOfDAsJisW8fz6NED\nOPRQ4OOPg7ZPPuFAPXIkt7sZbR9+CBxxBFN/338fIf7zH+Dii9nPGTPC1/bTT1k+5fnnw/u89RaF\n8+KL41le997L4pK//318XsoVVzCQH10kq7ISOOYYYP/9w32w5zx8OHDBBfH5L4sWAd/9rn/OzPz5\nFMFoZQCASQa+MjOAlspXaqehLIyRABYaY5YZYyoBPAvgLN8Ld4VLyt2eLkvKbbPzMICwS8oVjPq4\npJJiGHafJk3YvyZNgn64LqnoxL3aYhgdO/JYHToEd7Xr1nHQBzjIJwmGz8Lo2ZPH69YtmNuxciUH\n8Jyc9IIRtTAWLKCF0aQJH+3iUFVVvNMeNIjuKjdYPmsWizCKcBB1K/F++inv+Nu25YDtFmOcMYNC\ncswxYcHYvJl9Ouggxj6mTQva3nkHOPpo4JBD+Bm6gf7XX2eM5Zvf5DolLi++CNx6K9td19jq1XSj\nvfce8NprYcvk5Zf5Gd93H/CLX4SPd+edFMcvvgiXcjGGIlJdDXzjG+EbnY0bmUzwm98AP/95+Hj/\n938U4gMOiBesfOIJfv++8524cPzqV7wW0Zn+FRXAzTdTBKMTTtevB375S55vlGXLgIkT/e6+hQvZ\nT1823NKl/nVmAG7XDLrM01CC0ROAOwtgZWpbjJ3NkopaGNF5GPUNettZ3nZ7eXlwJxd1SSUJhhvD\nsAFvixv4dl1SSRP3gLBLats2/nBs393UWhvwBtK7pLp3j8cwevTg8169glTYFSsoFEA8hhEVDNfC\nWLKEGVcArQmbXbVkCfvQsiVLmxQWBtfJCgYQFwxrYQAcYD/6iM+3b+dgO2IEB8rly4Nr+L//8bV5\neRxg//Of4HhTpwInnEBxOvnkoIw8QLfW6NF0S82eHVh28+fz2IcdBpx9NoXA8swznBDZrRvjIq5l\n8uc/0y323e+yT9Y1VVoKPP44cNttdGX9+tfBgPjWW0H7YYfxGJa77qL77e23ud0KdU0NlwH+4x95\nvKuuCo63dClw3XUcqBcsAP7yl+B4f/87LaNx44DzzgunVY8bx2u/fj3Py1qypaXBnJ0f/hD461+D\nfWbOpID/858UoYULg7ZHH2WF5Qsu4J89Xnk5cNllPNcBA3g9LUVFfO9u3YDDDw/377PPuE9+PieW\nuokrjz/OG5Phwxn/steiuJgp38OGAeefH878mzOHqeDHH08RtSJZU0NBP+88ppg/+WTgeSgpAR55\nhOczbhxvGqwgL1lCYb/8cuCBB4LfT00NP4vbb2cyx6RJwfG2baMI33YbLdmPPw7Gn9WrmRhy//3I\nGFkf9N6wYTzGj+ff6tXTvS6pqip+4Lm5QZvPwqhvaZDaLAyRcFs0S8p1tUSD3vbLZuMXlqhgWLdT\nbRaGHbhswFuE/7txDNcl5bMwunblc1cwSkt5na1w9eoVxDFswNseb8uW4BraGAYQtjCqqyk0ts0V\nDBvbAGi1DBkS3AnPmUO3DUABcAVj5kxaCgBFwLp2Zs7k8Vq25HfjkEMCF87779OKAOiu+uCDYICa\nNo2CAYQF48sveT0OPJDfsRNOYIwE4I/6rLNoNZ16Kt/Hfl4vvsgJjAAHh7/+lYPCqlUccM8+m9+/\niy8GHnqIr3v6aYpS3748bnFxkDZ8113AT37C97r9dv5fVsYbgEceAX72Mw6gP/oRBxaAg1hODgfB\nK67g9+eFF9h29dXA9ddTdB95hJbJypX8DvzkJxygx44F7rgDOPdcvtfTTzO9+fnngcce47Gvv56f\n7/nn8zN64gleu5//nO69+fOZGffAA7xet93Gastz59KdN2ECP5fZs3mdv/51Wo9nnMHv7pIlTHy4\n6SYO6s89xwHfrnB5ySX8TP/wB+DGG4FRoyiMCxdyMD3wQOCee/h5338/Y1h33cX3PekkWku2MvSj\nj/LYxx7Lc//mN/l5DxrE6zt3Lm+ILryQ4nLHHTzGqafyevXqxRuLffbhAH/KKRw3rrySrtgjjqBw\nrljB6/7RR3w88EC2X3wxx7D8fFqf3bvzO96tG/Db3/L3vWwZ43ZdugDduk3HgAHjcccd43HDDeOR\nKXIzduT0rALQx/m/V2pbjGbNxmP8eD5/912/S8qdtMd9/EHvdC6p6FyLJMFwg95AEPi2cQk3TpHO\nwkgSjHbtAsHYtIlfFCC9YHToEKSn2oC3xc2Ucl1S+fn8cVsBjFoY1u1kM6Tste3ZM7AwVq4MBKNJ\nE/5Ili/nj2758rBgWLfOqlXsk/1MhgzhDx/gD3vffYO+W7fU4YfzB3reedzeqxdFbO1a9quykv0C\neEf55JN8/vHHFBDLEUfwLn7UKAbHb7wxuLb9+nHwHjCA5zViBNtOPpl3hjU1wOTJ3Ndei69/nUvn\nnn8+H29KpW60asX9Xn6ZA8X8+XR7AexP69YUpZkzKRb2WvzwhxxE7riD1sFvfhNc23HjgN/9jjcD\ns2ZxEAM4qI0cSatg2TJeI/uZ3Hgjr+drr9FV9txz7HtuLvCnP/EY8+fzur/0EvcZNgy45hq6ukTY\nJyvGP/gBB+wTTqB4vv12cCPx7LPAkUfy/QYNYv9F+P+rr3IgLS/nQH3uudzn8sspNIcfzn3eeYff\nFYACc8sttB7GjKG7LjeX/Zsxg4P7I49w0D/llOD6HXMMRaBjR/4m7Hf6mWfYj1dfBb7/fd7x5+Sw\n7bPPaEUtWcLP+MADg+/S97/P65abSzea/Q2fcgpfP20az+O444LvxSWX8Lv5v/+xj/bzAIDx4/ld\nLizk99H97Kuq+J1t357XzR7vZz8LEiP69w+uuWXNGmDr1gL061fw1TmJTEAmaCjBmAFgoIj0BbAG\nwFgA5/lemG49DNvmuqOA5LTa3FxaIlVVfJ4U9LZ3mnl5fEyyMICw66k+FoY1P30WhnWbbN7MARUI\nsqSM4RcpKYZhA96WqIVhf/wiQWptv378AvssjNWrA9ECwi6plSuDu34gcD1FBaNfP26vrg67qoCw\nhbFwIfe1DBsWBL7nzg2uhRvHsIOI/XENH05rpLw87KoCOKA99BA//48+4g/WctxxdEutWkW3iLVW\ne/fm9Zw5k4OJHewA4Gtfo0gUFvJO2FolAF/3979TrM88M/jeinCAeeghHvPRR4N9+vdnn8aM4Xf6\n5JODtgsv5J36WWdxIHW/7xMm0E3SunU4GSA/n8Jw3nnAtdeGF9Q65hge59//pnvI9g/g9vx8fteu\nuSbYLsJB88UXKVLuZ9W2Ld0on39OAch1RpYRI2hhupaq5dJLOcDaz8+Sm8uB/667EKNrV/bDx7Bh\ndDf5OP10/kXJzaVL0Ee7dhRKH/36hb/LLt260Q3pY8iQ4Lsc7cfhh/v3ads2/F12cX+fmaZBXFLG\nmGoAPwIwGcAXAJ41xngz2+uSJeVaEUA4VuG2iYTbkiwMN6UWCAe3o4Lhpta6guFaGBUVHCxtP1wL\nw9aRsiS5pPLyuH9JCQe80tLgbsd1SdmAtyXJwgCCTKmKCr6nFZqoYPR0okuuYKxaxf8tNhtq2zae\nl3V/tWjBY69cGRcMO+GvqspvYcyeTaGrqgoEDQgEw41tAPwcBw7k9o8/phvKcsQRHNRmzuQ5WcEF\nAsGYPDk88AO8m3zqKd5djxoVbO/Zk4J3+umBW8lyxhns++23hwddgHe3U6bwTvaYY8Jtd97JgeOJ\nJ2hZWJo3p/trwgS6mlwOOoixms8/D18jgK6U4mJaLVGuuopB/OjglZNDgfnxj8N9AHiOF10UFgtL\nfj5dQrme29CWLeNiYYmKhZK9NJSFAWPMGwA8X7swdcmScjOkgGQLAwjiGK1aJVsYrjsKCKfPukFv\nIGxhJKXO2u32h1GfGIb7I7NWRkUFX2d/zG7QOyoYnTsHWUhu0BsI4hhWSOzx2rfnNdq2LRzwBuIW\nhk8wbDDcHWwGDGAqaFQwWrSgQC1ZkiwYX3xBS8YdWEaM4N1xTg794C6HHsrB9csvKSzu+XbowIDl\n6NHhfU44Afje9yhMX3wRbrviCvbl0kvD1hsQZDdFB+RWreiyKSyM3xm2b0+Bz8mJD5bDhgH/+he8\nDBsWFkcXV9QVJVM0mGDUh+pq/rjc8uZRCyPJJRW1Ptw4RlImVFQwWrUKfPp1tTDsdmPC8QsgnFYb\nzZKKxjCigrFpE/tvLQ8gbmG4VkSnTkE6qRv0BgKXlOuOAjiIWSujvoLx1lvBZD6XgQM5gC9YQFeO\ny5AhDBKvXx8Wk549+Tm++ipdIC7Dh3Og3roVX8W4LEceSbfPmWeGvxcAt99yC60Ml06d6HcvLY27\nGYYO5XWIigVAP7dv9UKAd+G+O3HAfxeuKNlO1mdJubGKpLRanyikszBqc0m5czBsm2thJMUwXAvD\nFg207hm7HajdwnBjGK4w2Ml7RUVhK8IKSU1NPOjtxjCiFoZ1SbkBb4sVjDVrwoLRvTv3KSvje7rH\nsxbGokVB2qzFWhizZ/Nu3WW//Zh1c+CB4YFUhK+9776w/93us3w5P7+BA8NtF1xAa2CCJ+530028\nRjaw6XL++Qxy+ujePYhpKcreSqMQDNf15AqGtRSiLqmkGIZts/vVxyVVW5aUbXPdVdYtZRdPstTV\nJZVkYdjUWYuta7VlS3KWVEUF++cez7qkohYGkGxhNG1Kt87//kcrwnU77bMP4xFz5/Ku3OWgg2jp\nfPklB3uXIUOYyXPssYhx3nm8/lGrJDeXVsLUqXG3TosWzJ5x3VEWkfC1UxSl7jQKwfBZGFFRcF0P\n7toWUQvDdUnVVTBcUahrlpRtKymJu6TqIhg1NdzXbbOC4WZIWaxbKsnCWL+e290B3rqk0lkYy5aF\n0wIBWhJvvBF3t/Tty2v45pvh7CmAwd3//pfb3c8DYGD2nHP82ShXXslzdq+rZdCgeN8URckcWe9J\ndWMV0SynQ34mAAAgAElEQVSpulgR9bEw7CzpdBZGNOjtxirSWRjpXFLuXb+d0V1czGPZvGogEIyc\nnPhdsq0nlWRhRN1RQOCSWrEibhH06cN017Vrg/RYy4gRnOtg50VYRBhreOMNxhFc2rZlKmTUfWTP\n6x//iG93j6soSsPTaC0MVzB8LimfKLhtdq1vd45Gbi7fqz5ptdbC2L49WE3PYlNrfUHv0tJgRT1X\nMKyFYZdmdbFZUlGXFBDMxYgKRrNmPOf58+Nup549KRaLF8djDsOGcRDv2zceoB05ktaHnSnt8rvf\nMQXVFUjLxRfH00gVRWk8ZL2FYQXDrtNtA49RCyPqkkqyMKzraft2Htt10di22tJqo2Kyfn248KDF\nuqSibqecHL7X1q3JguFWo7W0b8+B35h47rwtMhhNqwUoFB98EMyitfTvzxhFeXk8M2j4cFofdoay\ny9ixnIPhmwSVLvVTUZTGTaOxMOwsb+ueqKvbybUigMC9FLU83DZfDCMp6G0tjKjbCQhcUlELAwjc\nUr7SIJs3h4sLWpKC3gBjFXPnst9u3wG6gd56K+5aysvjfqtWxV1F3btzqdQbbkCMli1ZByiasqoo\nyp5No7AwysvD7iigfi4pn4XhEwzbVltarS+GEc2EAgLXU3Fx/A7eCkZ9XVJFRTzf6JyAffbhhC9f\nEHjwYMYVfPGDyy5jtpEvZdS3EJCiKHsvjUIwrIWRbnJeOpeUKwy1CUZdLIyoYNg4RdTCSMqSAvh/\nURGP6x7PConPJWUL/1VUhCfMAZzn8O67LIgXxU56iwaigfiaCYqiKElkvWDYLKmoYNQnEypqYaRz\nSVkLw72Ddy0MX+qstTCSXFJRtxNAYVi5MlziA+Cdfn4+3UvRrCY7Ma66Oi4Y1nqITooDWMyub9/4\n7GtFUZT60KhiGD4Lw5j0LilfDMMX2AbCLik3TtGiBY9TU5NsYSQJhnVJ+QRj6dL4doBiMGNGeMIc\nQNdVSUmwpKvL/vuzHpKvQmZurj+jSVEUpT40WsHIyeGdeVVVepdUUgwjSTC2bYsLRpMmPIZNn3UF\nyFoYPrdTOpdU167+6qIABePDD+OCIcLj+Kp+inDWc7TmkqIoyq4i611SbtDbrdkPBFbG9u3hrKHa\nYhjFxX7BcF1SrmAAQfpsq1ZhF1I6C8PWhfJZGN27s5y2W53V0qsX3U6+AHZ07QJFUZTdRaMQDJ+F\nAQTCUJ8sKSsK7nrelqQsKbtfYaF/roW1MKKCYdfNjlaQBWg9zJnjn8hmFzmKltcA4qW8FUVRdhdZ\nLxg26O2WNnfbrIXhc0nZMh++LKkkC8PnkgL4/7p1ccFo04YWRElJ3IXUtSsD29Gif0CwSlY0eA1w\nBbJBg+JBeUVRlIYkYzEMEbldRFaKyCepv9FO2y0islBE5orIqHTHSWdhuILhszAqK+k+cucY1BbD\nSHJJtWzpF4xWrRgMX7EiPtGua1eu/xAt+gcEs6F9WU2tWoVXdlMURckGMh30/oMx5uDU3xsAICJD\nAIwBMATAaQAeFEkuL1dXwfDVi6rPbG4gvWC0bs36SVHBEAlmWUfdTjY111dOu08f1lw69dSkM1cU\nRckuMi0YPiE4C1zDu8oYsxTAQgCJuT11iWFE4xTpBMO1MJLExCcYHTpwGVFfGqwVjOjsa1tp1q04\n63L++XHRUhRFyVYyLRg/EpHPROSvImKH2p4AVjivWZXa5sVmSUXdTkDtLqnaBKM+MYyOHele8lkL\nnTvTLeVbwvPee+PrPSuKojRGdkowRGSKiHzu/M1KPZ4B4EEA/Y0xwwGsBXD3jryHa2GkEwxXGGw5\n7i1bkkXBJxg2DTZaYBCgUCxcGI9TAIEryhfAvvZari2tKIrS2NmpLCljzCl1fOkjAF5JPV8FwJ1h\n0Cu1zct7741HZSVTVps2LQBQ8FVbkkvKtm3aVD8Lo317lvsWie/XsaO/dDgQpL9qVpOiKA3B9OnT\nMX369Iy/T8bSakWkmzFmberfbwCYnXo+CcBTInIP6IoaCODDpOOcdtp4rFvHJURXrw63JbmkgB0X\njCVL4kX/gEAofG6n667jGhGKoigNQUFBAQqcxWsmTJiQkffJ5DyM34nIcAA1AJYC+AEAGGPmiMjz\nAOYAqARwpTHGJB3EuqSicy2AZJcUkCwY1iXlczu1b+9ffQ4I3E3RNSUAvodvH0VRlD2JjAmGMeY7\nadruBHBnXY5Tl6B3kkuqqCguGO7CRdHJdO3b83i+Wk2HHMJHOwtbURRlbyPrZ3q7Qe/oHAgbw0hy\nSRUV+edaAMDatfEUWeuK8sUpOnZkocOkFFlFUZQ9nUZTrba2tNqoJdG6NYsF+gLRNlYRFQxrWfjm\nWgAqFoqi7N1kvWC4Cyj5BMMWH4zGN9q25VrV0YKAAFNjfa6nJk1oSfiK/imKouztNBqXVFLQe/Nm\nPkaLi7Rty2qwBx8cP6a1IHyWxMKF8bUrFEVRlEZgYaSbuNeqlT+wDYSXQI1SVcVHtyihpX17dT0p\niqL4aBSC4SthDtDdVFjoF4y2bZkJ5bMWfDOyFUVRlPQ0CsFICnrn53Myn08U7DZf2x13AJMm7fq+\nKoqi7MlkfQyjeXPOs8jN9VsYq1ZxZbso1hXlm7V9wAH+dSgURVGUZLLewrBLoPpcUm3a0MLwZUJ1\n7crH6Cp4iqIoyo6R9RZG69Ys49G0aXziXn4+A9g+wRgyhI++Uh6KoihK/WkUgrF1KwUjWvvJCoVP\nMA46CPjgg+RJeIqiKEr9aBSCUVrKFFifhQH4az+JAIcfnvn+KYqi7C1kfQyjaVPAGM63iAqGXbjI\nxisURVGUzJH1ggGwgGBVVbyQoBUQn0tKURRF2bVkvUsKYI0n99Hl5ZeBY47Zvf1RFEXZG5E0axc1\nOCJijDFo25ZrWGRxVxVFUbIGEYExRmp/Zf1oFC6pioqG7oGiKIqyU4IhIt8SkdkiUi0iB0fabhGR\nhSIyV0RGOdsPFpHPRWSBiNxbl/eJlgTZG9kdC7w3FvRaBOi1CNBrkXl21sKYBeAcAO+4G0VkCIAx\nAIYAOA3AgyJfFSB/CMD3jDGDAAwSkVNre5NzzwXOOWcne9rI0R9DgF6LAL0WAXotMs9OBb2NMfMB\nwBEDy1kAnjXGVAFYKiILAYwUkWUA8o0xM1KvexzA2QDeTPc+Dz8M1NTsTE8VRVGUnSVTMYyeAFY4\n/69KbesJYKWzfWVqW1pEdI0KRVGUhqbWLCkRmQLAnRonAAyAW40xr6ReMw3ADcaYT1L//xHA/4wx\nT6f+/yuA1wAsA3CnMWZUavsxAH5ijDkz4b01L0pRFGUHyESWVK0uKWPMKTtw3FUAejv/90ptS9qe\n9N67/IQVRVGUHWNXuqTcwX0SgLEi0lRE+gEYCOBDY8xaAMUiMjIV9/gOgJd3YR8URVGUDLGzabVn\ni8gKAEcA+LeIvA4Axpg5AJ4HMAd0RV1pAt/XVQD+BmABgIXGmDd2pg+KoijK7iGrZ3oriqIo2UNW\nzvQWkdEiMi81ue+mhu7PrkJE/iYihSLyubOtvYhMFpH5IvKmiLR12uo1+THlAnw2tc//RKTP7ju7\nuiMivURkqoh8ISKzROSa1Pa98Vo0E5H/E5FPU9fi9tT2ve5aWESkiYh8IiKTUv/vlddCRJaKyMzU\nd+PD1LaGvRbGmKz6A0VsEYC+APIAfAZgv4bu1y46t2MADAfwubPtt2CmGADcBOA3qef7A/gUTEzY\nJ3VNrEX4fwAOSz1/DcCpqec/BPBg6vm3wbkwDX7enuvQDcDw1PPWAOYD2C9br0Xqu1gDoInzPhft\nwuvRMvWYA+ADACNT12IygCey6Vrspu/HdQCeBDAp9X9Wfi92w3VYDKB9ZFuDXosGvyiei3QEgNed\n/28GcFND92sXnl9fhAVjHoCuqefdAMzznTeA1wEcnnrNHGf7WAAPpZ6/AeDw1PMcAOsb+nzreE3+\nBeDkXXAt1gOoBLAFwHYArwBoubPXIvWZVSMlGPXYbwmAE+vx+pYAPgJwWOpa/A6c3LrXfC/AzMkp\nAAoQCMZe+RtJfX86RrY16LXIRpdUdNJfnSb3NWK6GGMKAcAwi6xLavuOTH78ah9jTDWAzSLSIXNd\n33lEZB/Q6voA/CHszLWoBLPx2oA/toEAfha9FqkMvawh5YL5FMBaAFMMKyF0BbAV2Ou+F/cAGAfO\n9bLs7PeisV4LA2CKiMwQkctS2xr0WmSjYOzt7MoshKwaGKOISGsALwK41hhTivi578i1sOdcBWAq\ngGHCiaUdAbwmIlsB9BORNqmY0moRWSEiv7BCkhrAfy8i60VkEYDTI/2eJiKXOv9fLiJzRGSLsBjn\ncBF5HEAfAK+ktt+Yeu0RIvK+iGxK+aaPN8bUGGNGADgKwBUiUgK66jrt5LWo7RplFSJyOoBCY8xn\nSN/HPf5apDjaGHMwgK8BuEpEjsWu+Y0kUeu1yEbBWAX+0CxpJ/ftARSKSFcAEJFuANaltu/I5Mev\n2kQkB0AbY0xR5rq+44hILigWTxhj7Fycnb0WuQA2pJ5vBDAawCep/9sCuBhAPoDlAB4DUA6gP4AR\nAE4BYO/ivg/+SA8CcCiAb6U5j3MB/BzAhSnL5kwAG40x30m9z9eNMW2MMb8XkR4A/g3gDmNMewA3\nAnhJRDqmDvcXAF8AuCN1bhfvxLVojN+LowGcKSKLATwD4EQReQLA2r3xN2KMWZN6XA+6bUeigceL\nbBSMGQAGikhfEWkK+twmNXCfdiWC+CTHi1PPv4tgIuOOTH6clDoGAJwL3mFnK4+CvtX7nG07ey1a\nAzhJRIoAHAC6dH4Nmu1zjTHzjDE1ADqAVZSvM8ZsN8ZsAHAv+F0DeO3uNcasNsZsBnBnmvP4HoDf\nmVRZHGPMYmOM6xpwP+sLAbxqjHkz9dq3AcwE8E0R6Q2KE0DReA4MXO7otWh03wtjzE+NMX2MMf3B\nz2KqMeYiMBZ1ceple8W1EJGWKQscItIKwCiwOnjDjhcNHdhJCPaMBjNnFgK4uaH7swvP62kAq8E7\n2+UALgHQHsBbqfOdDKCd8/pbwEFjLoBRzvZDUl+ehQDuc7Y3AydMLgRjAvs09DknXIejwSDyZ2Bm\nxyepz7zDTl6LYgAneK5FMVKZJam2w1LvX5T62wRgM1LJCKn3OM15/SA4QW8A0wBcmnr+BYCvJZxn\nKOgN4E8AyiLvuxW801sAxmBuTb22Q2r/4r3lexG5dscjCHrv7Pei0V0LAP2c38cspMbBhr4WOnFP\n2WMQkSXgWitTI9unga6vR1P/dwPwJYDWxvMDEJGpYIrhX1L/nwJmlOQZY2rc44nIG6DV8EfPcRYD\nuMz2R0RuBtDPGPMDz2v7gD/2tsaYstS2JwHUGLq3FKXByUaXlKJkFEMzfTKAe0QkX0h/ETku9ZLn\nAVwjIj1FpD2Y757EXwHcKKkVJ0VkQMq9BACFYIzE8iSAM0RkVCqw3lxEjheRHsaY5WBK7QQRyRNW\ncj5j1521ouw8KhjKnkSSuezb/h0ATcF6Z0UAXgBz1gHgEXBRr5ngIP5S0vGMMS8C+BWAp0VkC4B/\ngm4DgLGP20SkSESuN8asBBcX+yk4Z2QZGPi2v8MLwHlIGwHcBgbmFSVryLhLSkSuAwODNaAf7RIA\nrcCgXl8ASwGMMcYUZ7QjiqIoyk6RUQsjlUZ4NYCDjTEHgmmP54GzEt8yxgwGI/O3ZLIfiqIoys6z\nO1xSOQBapfLuW4AZIWchMLcfA9f1VhRFUbKYjAqGMWY1gLvBFNJVAIqNMW8heXq7oiiKkqXUukTr\nziAi7UBroi+YT/6CiFyAOk5vF13TW1EUZYcwGVjiOtMuqZMBLDbGFBkWt/onWC8naXp7jIaeQJMt\nf7fffnuD9yFb/vRa6LXQa5H+L1NkWjCWAzgilW8uAE4C0xiTprfXCRFg/fpd2U1FURSlNjIdw/gQ\nLDD3KZjTLmCBtd8COEVE5oMi8pu6H5OPJ53kb1chURRFyQwZjWEAgDFmAoAJkc1FoLuq3rz3Hh9n\nzYq3zZ0L7L8/sH070KzZjhw9eykoKGjoLmQNei0C9FoE6LXIPFldS0pETE2NgbvczZtvAqNH83m0\n6x9+CBx+OLByJdBzT15ySVEUJQ0iAtMIg947TXl5+P+amuTXPvAAH7dsyVx/FEVR9layXjBKSsL/\nb92a/Np1qVyrbdsy1x9FUZS9lUYnGLfeysd27eKvtXELn4Vx3nlAdq3krCiK0rjIuGCISFsReUFE\n5orIFyJyuIi0F5HJIjJfRN4UkbZJ+1dUhP8vK+PjyJHx105Krcv39NPxtmef3dEzUBRFUYDdY2Hc\nB+A1Y8wQcI3keahH8cFoDGPffflYWpr8hgccsFP9VRRFUTxkulptGwDHGmMmAoAxpsqwjHmdiw9G\nLYypqbXU/vvf5Pdt06Z+/dyyBaiurt8+iqIoexuZtjD6AdggIhNF5BMR+YuItEQ9ig9GBeOaa2hl\n5OQkv2l0HwA4/vjktrZtgSOPrOVMFEVR9nIyPXEvF8DBAK4yxnwkIveA7qg6FR8EgL/8ZTymTOHz\ngoIC3H9/AfLygP3287++WbO4GwsANm7k49atQNOm8fYZM2o5E0VRlCxl+vTpmD59esbfJ6MT91IF\nBv9njOmf+v8YUDAGACgwxhSmig9OS8U4ovub1183X03U4zY+7rsvsGBB9PXA0UcD55wD3HBDuK1r\nV6bdrlkDdOsW3w+ITwRUFEVpjDTKiXspt9MKERmU2nQSgC9Qj+KDURfS6NHA9df7XUsAkJcHVFaG\nt9XUAEVFFIqo9WHndQwe7D/epZcCq1Yl9U5RFGXvIeO1pABcA+ApEckDsBhc0zsHwPMicimAZQDG\nJO0cFYY33mDMISoKAJCfDwwbFt+nqIiB8Pz8uGCsWcPHrl397z9xIuMbl1+eeH6Koih7Bbuj+OBM\nAId5mupUfNBnSXzwQXx7RQUn+bVrFxeT9euBzp0Zu9i+Pdx2//18tPM7XN59l4/f/74KhqIoStbP\n9PYJRuvW8e12XkbLlnHBmD0bmD8faN48LgyDBwNHHeUvJ3LccXwck2j/KIqi7D1kvWD4Mp5+/eu4\nYJSXM0aRl+e3PsaMAVq0iFsYa9cC/fv7LQxbfuTww+NtIlpqRFGUvYusF4yqqvi2jh3jVsT27bQg\nmjaNtxUV0SXlszCWLwcGDPAL0+bNFCGfmKRj2jR/vxVFURozu6OWVJPUpL1Jqf/rXEcK8A+8Isx8\ncmdnT5wILF3qtzCKioD27f1zNLZsoSgkZV2dc07cKnHLkkQLHZaWAieeCJx6arqzUhRFaXzsDgvj\nWnAdb0ud60gBYcGw8yRqauKWxMCBfPSl1f7f/zFG0bRpXBhKSoBOneJCUlVFYdpnn7iFsWoV3VhA\nvKbV55/z0Zd1VV4erNmhKIrS2Mh0LaleAL4G4K/O5jrXkQLCgmEXTxoyJG5JdO7Mu3qfKDRrxhX4\nmjVLFgxfTKRFC3/cY+VKoE8fPp87N9x299189MU3Bg8Grr6alpCiKEpjI9MWxj0AxiFc+qPOdaSA\nsGDMm8fHjh3jwlBVRRHxWRi5uRSMpk39LqmOHbndneltYyItWsQtjBUrgiVgo2uL9+4NjBrFVN4o\nuakk5uefj7edcoouK6soSnaTMcEQkdMBFBpjPgOQLp8obUEON06xZEnwPOqSWrGCAWxf0LusjAO/\nTzBKShjfaNIk/F5WMJo3j1sYGzcCXboAp50WlFu3FBdzm61/5fLll3zs3Dne9tZbwOrV8e2KoijZ\nQiYn7h0N4EwR+RqAFgDyReQJAGtFpKtTR2pduoO8/fb4r1xRzZsXACgAELcwrrqKj76gtysYUTEp\nKeEMcCsm1gpIZ2GUlXG+R6tW8SVjt21j1pWP/v2BoUODQoiWpIC7ZfRo4KmnaAkpiqJE2V3FBzMm\nGMaYnwL4KQCIyPEAbjDGXCQivwPrSP0WtdSRAoCjjx6P8eP5/PXXg+1RYbj8cqazJlkYLVvG24xh\n0Lp16yC+0aoV29JZGFaAfIKxdSuw//4UHmPCsYwNG1hld8OG8D6bN/OxSRP2wa2m+/77wJtvMs6i\nxREVRfFRUFCAgoKCr/6fMGFCRt6nIeZh/AbAKSIyHyxG+Jt0L3ZjGL17B8+jFkb//sA3vuG3MNw5\nGm5bcTED6Tk5cXdVbRZGixYUIZ9gtGsXDP4WK059+8YtjOJi9r9bN1bUdbFi8s1vxq/NokWBZaUo\nipJpdkfxQRhj3gHwTup5EepYRwqIz8MYOpSPUWuhpoaDtM/CqKwMAuLuIL59e7A6XzSDqqwsEIyo\nhbF9e3IG1bZttDxat6a7q1kzbi8v5/t36xa3MIqLWVCxbVugsBDo1Sto27CBx/LNR7Hxk7vvZl8V\nRVEySaOa6V1TE7h4otaCtRR8FoYVjOg+FRWBYCRZGL7Z4enEZOtWWh5WMCzW9dWxY9zC2LKFYtGt\nG0uVuKxZA4wYEVTVdfnud/m4cmW87amngE8/jW9XFEXZUbJeMNzMJWNoRQBxYbAWhi+ttqqKMYWo\n9VFREVgAUQvDdUklWRi++MbWrbQwWrUKFzQsLeW2du1oUbgUF1O4fIJRXMyYiE8w7PGXL4+3XXih\n342lKIqyo2S9YLgWxgsvBDOpfRaGdUnVx8KwAWafhWFFIWphpLM+tm2jhdGyZVgwrJD4BKikhILR\nqVPcXVVayqyrwsJ40HvDBqB7d6YU+4gKk+XJJ+tfH0tRFGW3xDB2Blcw3LkNUUvCJgWcd17dYxiu\nYNTHwrAuKd/McdfCcAPiNlPLJzI2tbdlS39bp048XlFROLV2/Xq6q3wWBsDXWyF1+3fRRTzeOef4\n91MURfGR8dIgIjJVRL4QkVkick1qe50LELqC4Q58PtcTkD7oXV8LI8mKsG3RYobGJFsYNrPK58ay\nguHLyLKxj7Zt44UON22iYEQtjLIy9q1bt/jysraUiZ1E6DJvHnDEEZq+qyiKn0y7pKoAXG+MGQrg\nSABXich+qEcBQlcwcnKC53l54bYf/5jZQrUFvV0xKS+vm4XhE4wWLfz7NG3KfvoEo2XLZFGwFkZ0\nISfb1rp1vNDh5s1ckjZqYRQVAR06AP36AcuWhdsWLeKjLbPi8sorLNS4eHG87X//Az78ML5dUZS9\nh4wKhjFmbao0CIwxpQDmAuiFehQgdEXh+OOD57m54cG/utof2LbHsG31tTDy8nhsO9vcbYvuY60I\nIB70tpZHukB5OgsjmnVVXc3jDB4cLymyaRPLnfTpExeTpUuBww7jCoRRrLj4BOOCC7gyoY9x4+Lz\nRxRF2fPYbUFvEdkHwHAAH6AeBQjdLKkRI4LMn6iFUVVVe1rtjsQwRJLFJOqScgUjOqlv2za25eVR\nfNy+J7mxgEAw8vPDFkZJCUWmTZuwkACBYHTvHs+uKiriwO+zMNatYx+iVokxFB4rUi6rVgG//z3w\nsme+flERcP756uJSlD2F3RL0FpHWAF4EcK0xplREokNI4pAye3ZQGsSYAogUAKi7hWFMIAzp0mqT\nRAEIxMSKgRv09mVWAXFLwoqCSNDWunW4zWdhlJQEFkZ04aY2beJCAgQuKZ9gbNoEHHoo38cew7J+\nPdui5de3buX16daNcz7s2iNA8Nr33mN5FpcpU4BnngF++lPggAPCbZ9/DnzyCXDxxVAUZSdp9LWk\nLCKSC4rFE8YYex9aWNcChAMHBoLx3HNB0DYa9E6yMCorKSS+lNuohRG1Fuya3kliEj2eFRLf8awo\nAEHmlRUMO9kvnYURFQwbKI+6qoDAwujaFZg929/WpQsFIioYo0fHBWPjRmZn9e1L68MVjMJCzjh/\n7z3EsAH3zz6LC8Yf/gA89phfMDZvDmJEiqLUzp5US+pRAHOMMfc52yaBBQiBWgoQRlfccyfuuW3W\nwrDbrRukvDwYeKJi4ga9o4O/ay0kWRLpXFI+MbGCEc28suVEaoth+CyM5s15vq54WgujTZt4ZtXm\nzRQM35wPa2FEXVL2eFYwXNatA44+mplabpwHoHWTk+OPidh++eaKHHQQcNZZ8e2KojQsmU6rPRrA\nBQBOFJFPU2t7jwYr1dapAGFSaZCoS8paGCLhNlcwfBaGO9M7nUuqLjGMdPv4LAy3zRYzdC2M6upA\naJIsDJF4m7Ui8vP91ke7dnHBqKmhMPhcUlELw2X9eqBHD4pTVIDWrAGOPNK/wqA9jq9t+fLksiZX\nXJE870RRlMyS6Syp940xOcaY4caYEcaYg40xbxhjiowxJxtjBhtjRhljNicdwxWMiROBZ5/l8yQL\nw7ZZwYhmQkVjGOksjGgMw75PZSVf7ytYmGSVWFEA/BaGL4ZhLY8mTeKuJzf+EBWG2gTDWhjuqoCb\nNvH1++zDgd5NNrCC0a0bXVAutq17d38drKOO8ovC0qXAyJHhRbGA4Ho28XwzV68GHn7YvzhVeTnw\nxBPx7Yqi7DqyvjSIO3C99VbwPBrDePbZYLlUVxhqszCSYhiuYLgxDHu8pOypJJeUa2EkBcSjFkZx\nMQdxIG5F2PpTQFwY7CDuy6CyLqnOncMWwfr13Jaby/02OxJuXVI27uHiikk0wJ5kYZSUUBhHjoy3\nzZ/PUiibNsXdcx99xMc5cxDj3XeB73zHn967YAHw9tvx7Yqi1I+sFwxfWW8g7pICAsFwYxU7E8Pw\nuZfSxTaiQe8k6yNqSdjJedHt1hoA4oJhB/GkNp+FUVMTlFLv2DEsGOvWBUvHdujAY1isKHTuHB+Q\nbbmSpEq7hx/O4Lf7OS5bRkumX7+4hTFnDmMY/foBCxeG2z77jIUYbeKDy/vv8/Hjj+Nt48YBJycU\n1H/+eQqKoii102gFI+qSGjIEuO02PnctjGjq7I5YGK41ky5OkS7onc7CsIHtqIVhixICfpdU21RB\nlagwbN7MOEV0u527kZtLQXGtiA0bkgWjsJDWRZcuccFYv57urahLqqSE16ZbN+7nlihZujQQjKiF\n8f3DzhgAACAASURBVOWXzMIaODAeLP/4Y04gTLIw9t03KE7pYo8TTQAwBvj2t4Ebb4zvU13NygG+\n8jOKsrfSaAUjamE0bx6UDolaGOliGEliEnVJ2bak7b62ugS9jQnmWkQtDBvYBtjuTgR0xSQqDFZM\nrOVhM8Zci6Vdu7BgWJcUEBeMlSu5qJNPMAoLKQpRl9Ty5ZxpLkJxcIVhyRJu22efuIWxeDFXH4xa\nH8YEbqfCwrBFVVrKkibXXAPMnBk+XnFxMLt9xoxwm0059lX7nTKFQvLSS/G2N95gPE1R9jYaTDBE\nZLSIzBORBSJyU9LrXMEYPDh4Ho1huCm3mYhh2OOlm2sRDXonuaTcoHdFRTBHJC+P2+x7pROMLVuS\n4xs2IJ6Tw/ey+1nLA+Djpk3BPukEY/VqoGdP7lNaGpyXMRy8u3aNWxhWMABmV7mCMW8eP0trYbgz\nwRcvZgyjX7+whbFmDa9Pr17AoEHh0iYvvwwcdxxwzDFxC+OVV9h2/PHABx+E2yZNAn7wA7q+oum9\nEycy/vLcc4hx/fXApZf6CziOGQP86Efx7dXVwNSpyWXloynJipKNNIhgiEgTAA8AOBXAUADnpYoS\nxnAFY8wYfDWJL+qScst4uxaGa0WkKw2Szlpw96tLuq09XpKF4bqkrDvK4loZNrYB0JXkS6sF/BaG\ntT7cwLdrYURdUta1BDAm4QqGFZMmTcKxjy1beJ4tWsQtjBUrgjXYe/QIt1m3k1373H0va2H07x+2\nMBYtCiYM7r9/2C01YwZw4ol0S375Zdjd98ILLE9yxBEsoGgxhvGLsWNpffz3v0FbcTGtiEceAaZP\nDydefPIJBfgnPwH+/GeEmD6dovDUU3F32kMPMY5y2WWIceON/Ax9rrZf/5rvFaW8HLj11nicB2D/\npk3zl2SpqoqXd1GUutJQFsZIAAuNMcuMMZUAngULEsZwReEXvwAefJDPoy6pzz8Pftiu9ZEusJ3O\nXRWNR7gxjGicwv4w62NhWDGxhQctUcGwYuKzIlwLw4pCdTXFye7nTt6zczCAuEsqGsNwl5G1QW+A\nr7GZUmvX0roA4kHvVatolQBx68MVkz59ApdQRQWFpXfvuEtq4cJgDfMhQ8KD67x5wH778ZoPGBAE\nxY1hhd1jjwUOPjjsrnr3XX4Gxx3Hdnem+kMPceLg0KF0w7lB9gceAK68Evja14D//AchfvpT4P77\nue+bbwbby8qAO+5gYP7f/w5f2xUrgEcfBX74Q+B3vwsf77XXgHvvZSqxK2j2vR59lOu/uNZJTQ3w\nrW9RQKNpxsXFFM7+/ePxnGXLgFNPBe66CzG++IKi5ZuA+fnntOJ8FtKCBf6VIgG6Nn37GJPshlYa\nnoYSjJ4AXM/xytS2GO7dHRD40KMWBhDMEXCFIeqS2pUxjCZN6Pax/diRoLeda2FxA9+uYEQXZIrG\nMKyY2HiItbZcwbAptUBcMFxRcF1SlZV8XxtgdwXDuqMAPrpzNFzBiFofK1cGgtGzZ7Am+fLl/D8v\nLxAMK8auhTFkSHgQt4IBsNy7dUutXs3PpndvusU2bw7ccG++yYB3kya0MGzKLgD885/AJZfw+aGH\nBrGPmhoO+GPHMvtr7tzgeLNns//f/jZw0knhuSJPPskU4iOPZOkVNy5y9910b918M11r9tpWVQHX\nXktr5de/Dg/ks2dTDGbN4vX517+Ctvvu4+f9wQfMDrPWoDE8p8MOo9j97GfBPhs30mU3ciT3d9PX\np04FCgr4+Z1+etiSvf9+iszNNwM33BB8VhUVFLLjj2dJmH/+M9hnxQq+z4ABFHH3c3z7bd4U5Ofz\nmPZ3ZQzw+OMUuuHDw/3bsIFiO2wY8L3vhSd1LlzIpYqPP57C68YNJ08Gzj2X/ZwyJdz3v/6VVulN\nN4VdnOvX83O4/HKKuPv7mTMH+PnPKayTJwfjVnU1byxuu42ftWsRlpQAL77Ixd+efjp8vFWrWDrn\nD38A3nknGLeqq5n88eCDvGFYuDDoe2kpr80DDyBjZH3Qe+PG8Rg/nn/A9K+2+xZQsv9HJ+7VxSUV\nbUtySbkxDCDslnLb0pU+b9Ys+PLaOlIW18JwrY90FobrkooWFGzTJvDP+4Le9svmpum6gmH3sQIU\nFYxu3fi8fXsKnT2vqIVhBWPLFg4E1tLp1SvIoLLuKHtOLVsGIrRoUWBh7Ltv8MPbto2v2Wcf/j90\naDAIffwxB3wR9n/o0CDQPXMmqx8DwCGH0NVkDH+Qs2dzP4CPVkw+/zwokdK8OWMmdn7HM88wgysn\nBzjlFLqEKit5zPvuA667jq8bO5avBXjz8/jjjIl06sRKzA8/zLYnn+T1O+UU1tt6//2gwvBNN9HC\n6NSJLtrx49nvwkLgl78E/v53CtrYscAtqZVmHn2U1/fee2nJvPACrS9jePxvfYsW/MSJFLDiYlod\nF1xA190TT9AaO/98vtfEiaxS/MEHtNamTOHAV1xM0dy6lfGpKVM4oD/8MAfOo49me3ExcNVVPObD\nDwN33snB/U9/4n6ffspzf+kl4OyzOVA//TT7eOml/PvTn/jZNW/Oc+7RgyJ0883A1VdToA84gNdq\n2jTeVNx6K3DCCWwfPZqW2FVXURSvvppC9sILFMLcXIrkkUdydcpBgygMhxzCz71fP24/+GC6G8vK\n+L299VZazqefzj5dey1vNr78ktbsgQfymD16UJwqKzmPrG9fWoD77svXvPoqP4Prr+cN2cEH8/t3\n0UVMMZ86lefSowfQu/d0tG8/HpdeOh6PPTYemaKhlmhdBaCP83+v1LYYrVoFxQfdelq+eRj2jiQa\n9LaikJMTDAo5OWyzgeao9VEXCwMIBKN16/gcjXQWhhUTdzsQtzBs4DhdlpTrkvIJhmth2IHalm63\nfd60yS8YruUBJFsYIkEWVZ8+vLvv0YNtrrtq1SqKhC3x0rOnXzAAPv/yS+6/aBF/zECQcltTQ+EY\nMCDIkNt/fw4eAAd6O/ADHDxmz+aP9rPPON8DoKDl5PDud9s2vp8V40MPDQb4mTM5WFhGjwZef52D\n7bvv8g7Tnm///nQjWQv0xBPZdtppwPe/TzF74QUOnvY6XXstB6rLL6dVYcWjVSsG0seN40A5Zw7w\nj3+w7etfB377Ww4qixfzLtsK6x130Bq76SYKxrRp/F42a0YRO+ccDkxbtvD9AA7SZ5xBMS0t5Tmd\ncALbHniAg2CvXvz+TJ7MQQ7gAHr22cCvfsUB7c9/5u/m4IM5sF15Jb8vd9/NO3uA53nkkRTTdu0Y\nY7LC/+qrvIueOJGf1/PPBzd+xx/P43z0EdvttT3kEFpRjzxCMZ01i58twOv67ru8A7/iCn5mtjLE\nxRfTulu+nIkQ9kYC4JgzeTJ/H48+GtxwXXEFz2faNH5+Rx0VHO+223jTsmABRc2eEwD88Y+0WCsq\neG3c+OWWLfx+tmvHpBB3wbg1a2iJ9+sXxBqBYOmBrVsLMGBAwVfXSCQzxQcbSjBmABgoIn0BrAEw\nFsB5vhfWdR4GwC+fbfO5pOzs7MpKfhhJLiljOJD66kxFBcPdL+qSSlcaxFoLUcFIsjCaNWO/7doe\n0dIg9njpBGPTpnCmmc2UatEimOwHhIPedRUMgM/XrqVguNaHa2G4QgJw8LGT7qKCsd9+/NEddVS4\nrXVritrKlcyWcs9p6FD63AGKglsNd9gwDvrr1/N62R+yCIXB3nEPGxbsc9hhFKW1azkAuW2nncbB\nurKSFsphhwVtl1zCwbZNG2ZiWYFs3pyDyKhR/I64qb7DhvEOvkcPJng4xUcxbhwH4quuovXhfqef\nf56WROfO4Zuqtm15h/+Xv1D03IrBY8bw2s+axfe0N1UAB7VPP+X3csiQYHteHgVyxQr20d2na1cO\n+PZmzGX//ZkQ4OOAA/ylXnJzmSZ9zTXxtjZtwufp0r8/rRUfxx7Lvyh5eRQQH7m5dOH56NqVVpyP\nIUPC186Sk0MrwkebNsmLlHXvHoifi0gg2ruDBhEMY0y1iPwIwGTQLfY3Y4xn/m56wbAWgfXT2sEr\naeKebauoCO7yfe4qWxLdfvFdi8C1IoC4S8pnYRgTD3rbPqcTjNLSQDBskUEbT0jKknJLhgDJLikg\nyJTq1o2vsdaHG/T2CYb16xYWhu+4e/akIFRXcz8bRG/ThttKSoIUXcugQbxzAygKrkWw//6849q0\niefv9n3oUA7+CxbwGJaBA/ne69ZxX3eAP/poDp4zZ9K6sIM4wLvW6dN5ru4+zZvzrvv113neP/5x\n+L1at6ZboU+fIM4D0A3z/vs832hm1JgxfI+OHWmVufz+97QIOnUK969FC/q7ffToQX+3j6FDaU34\nOOoo/wDVpEn4c3XJyQnfMfvalT2XBothpIoQDjbG7GuMqVO1Wpfc3KDNDoi+tFrXJRVti1oYvtnc\nQDjmkOSSAuIxDLcPeXnBj8ndJxrDcF1SW7eGTVYrGGVlwQqCdrvrknIHrrZt/S4p21ZczD87AxxI\n75Jy60m5WVJAsCTshg18H9s/exe0bBndT66FYQPYxsQtjBEjeKe7eDFNcXcAPfJI+s+jFkZODu8i\nX3uNghY93urVdDEMH44QNlA9ezYHWZdTT+Vd/YwZYStChJbElVfSVeOSk8O7+nfeCYTdZciQuFhY\nOncOn6uiZAtZH/SOZklZk9K1MKKxjKSJe7YtaRZ4UpzCtTCiQe/ofj6XlLsWhj1eUpZUkoUBBHMx\nXOsCiM+1cEUhnYVh29avDw9e7dpxe00NBcPGNoBwPSnX7QQEghF1VQEUjOXL4xZGp04U+sJCxivc\nAX7IEApCVEgAWgizZ7PdtTAABnwfe4wuLfeONyeHlsTvfx8XjBEj+F37xz/o13c54wz2/bLLAqvJ\n8r3vMfbgZh0pyp5K1gtG1MKwQWA36B0thZ1kRQDJYhKdnBd1O9XVwvC5pNz4BRAXjHQxjKiFUVoa\nj1NYSwEIz6ewbb55GO5+0QE+N5fvZcXEPZ5bHiS6nxWMqCgAgbsqGsMQoTDYOIYraL16sc+zZsUF\nw872XrAgbGEAHPynTw8HLy2nnUZrJupHFmEQ+gc/iPueu3RhHMM3R6FzZ2YeuVadouypNCrBaNMm\nuJNzg96VlfHgXJJLyrUIkoLe6SyMugpGbRZGXbOkXAvDuqR8FoYrGG4WhSsmUUuiQwcOyOvWxd0j\nNvAdFSDrkjKGLimfhREVBYD/r14dTre17Lcf0yf33z/simnShHGC11+nS8pl4EAKhkjYZQYwzx+g\nOET53veYEeMLSI4YwewedQcpip+MCYaI/E5E5orIZyLykoi0cdpuEZGFqfZR6Y5TUxPMCG3Xzl9B\n1p1PAaR3SdWlMKFvroVrYUStBZ+Y1GZhuFZEXbKkgLBLKmphbNnCQTxJMCoq+OgOrnbVPbe0ucWW\nAHFLhgC0AEpKKBZ20SeLFYxVq+IZHT16cPuCBXFrYcgQ+vujbiKAlsTHHwcpsO41zMmJiw/Ac9m0\nCfjGN+JtubnAmWfGtyuKUjuZtDAmAxhqjBkOYCGAWwBARPYHMAbAEACnAXhQJPmeLicniGPYlFIg\nHPR2twN1y5IC0ruk6mphuIO/a2Hk5XEfmyHlikJ+fuAmSicYdta2xVoY7sJK9r2aNqUwRQd4m1Zr\nRcF137mCEbUwOnVi/CLqkmrShG2ffRYXhe7debwZM2gtuPTowXz8du3CVgkQ3O27GVKWXr346BOT\nTz9l3ryPdu3UUlCUXU3GBMMY85YxxlaL+QCcnAcAZwJ41hhTZYxZCorJyKTjJAlDbRZGOpdU0vKt\n6SbnWQsjan248QhXMGywdfNmDvLunbh1BQFxa6FFCw78xgSLHVlsDMMXVLaWRJKFMXduvK6PFYyo\nq8ptW7YsiBtZunThhKWoKOTksF+vvBJP1xw2jJPvTjoJMY44gvnsvlx4OxHLtbTcY0atFUVRMsfu\nmodxKYDUfFn0BODUDcUqJNSRAsKximgpDzdLyrUw0gW9kyb1pUurrc3CcMt8uANbnz68u4+Kgpu2\nGhWFNm04MWr7dg7Abt+tS2rTpvjdfW2CsXEjZ+K6WLdTZSXLXLj06UMrYvPmeDxi2DAGgH/5S8QY\nMoT9jMYc+vdneQmfYHToEMymjnLQQXF3lKIoDcNOCYaITAHg3usKAAPgVmPMK6nX3Aqg0hiTMCTU\n0sFcvzC4lkdtFkaSS6quQe/aYhhlZexLebnf9RTNamrfnoJhTLytY0cO7lEhAQKX1Jo14cllQBD4\n9gnG5s2MH0QnXPXowZhDp05xi+XEEzm4H3ZYPAvt5puZ1eSb5TppEl1BPnfQhRfGtymK0njYKcEw\nxpySrl1ELgbwNQAnOptXAejt/J9YRwoAysvH4847eddaXl6AvLwCAOktjKZNgwE+XZaU27azMQxr\nXbgDpZ0fEc1qatGCrysriwuDnWWdJBilpRSMUZFUgbZtOY+hadNw3CM/n3276y7OWHYZNozHmjs3\nqD9kOfZYZhmNGYMYBxwQXynPvR6Kouxepk+fjulJ9Vd2IRlzSYnIaADjABxnjHGqKmESgKdE5B7Q\nFTUQwIdJx2nXbjyuu44umAkTki2MqGDYoHJd52HYNFhbR6quMQxbxym6EJJt81kYQOCWirbZ+Ea0\nxIdt++wzpqdGXVKDBnHS2aBBYdESYVbQpElB0TdLTg4LvL3xRhBctuTlcba0oijZT0FBAQqc4mMT\nkopt7SSZzJL6I4DWAKaIyCci8iAAGGPmAHgewBwArwG40hjf2mDEuqSqqjjA2cEwamEklf9ISqu1\nmVe2HIZdInX79rqnzgKBeylqRQBBhpKvze4XLeXRpQtTVqPbAU5QmzePVkFUMI49loLhqwFkaxn5\n5h6cd15yHSJFURSXjFkYxph907TdCSChpmQYG/T2BbbTuaRqKw0SdVUBwQAfFYVt21iNFIi3dejA\nuQXRFFggPPhHYwTWwohaEj16BNlJ0bkRQ4eyRDMQn39gS6ZEaxoBLIH96KPBAkSKoig7QtbP9LYW\nRlQUapuH4Qa2fWm1USEBAsGIup0GDQosjqj1YecruKvZWeziQA88wPIWLp07c0JaWVlYaHJz2efL\nLosHqe38hdNPDywjS8+ezDSKximAoEiezktQFGVnyHrBqIuFUVUVHkDTuaSaN6fFEBUSIIg5+NxO\ndvW0bdvCba1asdSEu2Kdxa4DccIJ8fjBF18AN94YL2MNcFUxILwutMUYLhPqY+zY+DkpiqLsKrJe\nMJIsjGgtqSQLIyoYdg2IdBaGb5GkZs2C4LYbj7DB4iTBeOMNupiiLqnfpAq6RwvnAayXlZsbXqtZ\nURSloWmoFffqjHU9RS2CpPkZAOdC2PIa0f3sRLaoawlIFgyA8yPWrYsHsPfbj33ZsCHukmrZkrOo\n7fKlLraEto1JRImWbFcURWloMm5hiMgNIlIjIh2cbXUuPrgjQW87IxqIWxLt2tHCiMYpgGBOgk8w\n+vblPAdjwgLUpAkti0WL4llNtjzGunVxC8OWtIiW3VAURclWMmphiEgvAKcAWOZsG4Kg+GAvAG+J\nyL5JqbW1Bb2NibfZGdFAXDDszGefhVFRwYXlW7eOC0a3blwTIT8/HnPo25f7RddYcBfvic6WBth3\nRVGUxkKmLYx7wMl7LmehHsUHkywMO2jbWkhRwbAr0EVdUnY1OZ+FMXYsMGCAX0y6d6dgRFNnAQrS\nnP9v72xjpKrOOP77g122W2BZeXENtMLGKNiqUHlLwUIosTYNJJo2+sXaJm1TE9vGD1QqTeCDSbGk\nsTZKE02tCVYUmxYhQQWk1ZgApYKyKlgVmorAqhXarNKGl6cfzrnu3Zk7u7Mvw8zsfX4JOXfO3Dt7\nz8PMffKc5zz/83r2ZvaLFsHixaVG5ziOUz9UstJ7KfCOmbUXqJf3SXzw7bdDLUNzc3enkPDRR32L\nMBLNpSyn0NISJC+ypqQuvjjsz5zlMF58MbSF1dIAzz1XamSO4zj1RaXEB38G3EWYjhoQY8as4skn\nQ9L51KmFwMJP3ps0KUz1nDnT/eGfaC5BscMYNSpEH1kRRktLkOXIchiHD4cVT/PmFd/j+PEhuX3D\nDQMZqeM4Tv+oCy2pUuKDkr4ATAZeiZsjTQL2SppNiCjSqd4exQdnzVrF3Lldshhp0kV46aroxGEk\n8h/pXELiMEpFGInDSKvOAixZAg8+WLwSCmDnzlBFnZJycRzHOW/UtZaUmb1qZq1m1mZmU4AjwAwz\ne48gPniTpAZJU+hFfDBJbhdOOwEcOhT2dS61R8WRI8W1FuVEGCdOhFxHmmSVU2GtBYS8h5lXUjuO\nM7Q5X3UYRpiuwsxel5SID56mF/HBZPlslsMA2LAhPKjTD//kwf3qq9kOo7Oz++54CYkg4NmzxWKB\nyZLZo0d7H6zjOM5Q5LxUesdI48PU65+b2aVmNs3MtvZ0beIwsqQ8JkwI+zVk5RwgRAmF1zQ2hs8q\n3DYVuqTFs9Rlk8/fvr3nsTqO4wxV6qbSOyvCmDkTzp3LzkdMmxYe/IURhhScyMmTxXmK5uZwjVmx\nw0hWQE2dOvAxOY7j1CM1ryXVU4SRvJcVYTQ0ZDsMCH0nThQ7meHDw2cWVnNDWI3V2urLZB3HyS91\n4zCycg6JyGAph9HZma3e2tiY7TCgWDY8zbFjYb8Kx3GcPFLXDiP9Xl8ijMbGkNzOchi+0slxHCeb\nijoMST+MAoPtklan+ssWH0xyGB9/XJxz6O+UVGNjqB7PqqlwHMdxsqmkNMhCYAlwpZmdkTQu9vdJ\nfLCcCCMr6d2Tw2hqClugZjmMpELccRzH6U4lI4zbgNVmdgbAzD6I/X0WHzx9uu8RxogRwWFk5TBG\njQo5DI8wHMdxyqeSDuMy4MuSdkn6s6RrYv9E4J3UeT2KDx4+DA88kB1hdHaWFgvctAnWri12MtC1\nZDararujI3ym4ziO051Kig9eALSY2VxJs4Angba+/o3161dhFnamGzZsIWnxwXXrQjt6dHbhHhTX\nUwBs2RLarAijcGc8x3GcWqeuxQcBJP0A+GM8b4+ks5LG0kfxwUceWcXq1aFwbvr07HOyIoxly4JD\nyXIYya57hTvkOY7j1CN1LT4Y2QgsApB0GdBgZv+ij+KDDQ2hmvvUqeLppfvvhxtvDNpPhcntzZvD\nSqis/StOngxtWsXWcRzH6ZlKOozfAW2S2oHHgG9BEB8EEvHBLfQiPvjaa/DCCyHpXZjDGDkyrHZq\nbi6un0ik0D/4gCLGjevniBzHcXJMxRyGmZ02s1vM7Eozm2lmz6feK1t88OqrQ5uV9H7oIXjppeyp\npTVrQpu1R8XBg3Aepvscx3GGFDVf6X3VVcEhZC2rTXa4y3IYTzwR2tbW4vfGjoUFCwb3Ph3HcYY6\nNe8wmpqCFHlWhDF/fmgLNzsCuPba0Hpi23EcZ3CoeYeRSJq/9VaxwzhwILSJ9Hia228P7eySJYGO\n4zhOX6iYw5B0taSdkvZJ+qukman3ytaSgqAldepUcSQxZ05oH320+Jq2Nt821XEcZzCpZITxC2Cl\nmc0AVgJrACRdQZeW1NeAtVJ5j/XCorrLLw/t3XcP0h3XMOejKKdecFt04bbowm1ReSrpMM4BSQZh\nDF3FeUvpg5ZUTwwbFqKIFSsGequ1j/8YunBbdOG26MJtUXkquUXrHcCzkn5JkAz5UuyfCOxMndej\nlhQEp+A4juNUl0ppSa0AFgM/NrONkr4BPAyUlBJxHMdxahv1UGQ9sA+WTprZmMLXkpYDZmb3xP5n\nCLmO3Rmf4bGF4zhOPzCzQV/yU8kpqXclLTCz5yV9hZCrgKAl9XtJ9xKmokpqSVViwI7jOE7/qKTD\n+B7wa0nDgf8C34egJSUp0ZI6TS9aUo7jOE5tULEpKcdxHGdoUZOV3pKul3RQ0t8l3Vnt+xksJP1W\nUoek/am+FklbJb0h6VlJzan3MgscJX1R0v5on1+l+hskPR6v2Skpve9IzSBpkqQdkl6T1C7pR7E/\nj7YYIWl3LHBtl7Qy9ufOFgmShknaK2lTfJ1LW0j6h6RXkuLn2FddW5hZTf0jOLG3gEuATwEvA1Or\nfV+DNLb5wHRgf6rvHuAn8fhOwj7oAFcA+wjThpOjTZKIcDcwKx5vAb4aj28D1sbjmwj1LlUfd4Yd\nWoHp8Xgk8AYwNY+2iPfXFNvhwC5CXVIubRHv8Q7gUWBTfJ1LWwCHCLuWpvuqaouqGyXDSHOBp1Ov\nlwN3Vvu+BnF8l9DdYRwELorHrcDBrHEDTwNz4jmvp/pvBn4Tj58B5sTj4cD71R5vmTbZSFiGnWtb\nAE3A34BZebUFYQfObYS9mBOHkVdbHAbGFvRV1Ra1OCU1EXgn9foIvRT21TkTzKwDwMyOA4kASqEd\nkgLHiQSbJKTt88k1ZnYWOCnpwsrd+sCRNJkQde0i/BByZ4s4BbMPOA5sM7M95NQWwL3AMkI9V0Je\nbWHANkl7JH039lXVFpVcJeX0j8FchVDTy5IljQT+QCjw7FRx3U0ubGFm54AZkkYDf5L0eYrHPuRt\nIenrQIeZvSxpYQ+nDnlbROaZ2TFJ44Gtkt6gyt+LWoww3gXSyZdJdOlQDUU6JF0EIKkVeC/2vwt8\nNnVeYodS/d2uUVjOPNrMPqzcrfcfSRcQnMU6M3sqdufSFglm9h/gL8D15NMW84Clkg4B64FFktYB\nx3NoC8zsWGzfJ0zbzqbK34tadBh7gEslXSKpgTDntqnK9zSYiO6efBPw7Xh8K/BUqv/muJJhCrHA\nMYah/5Y0W5IIe6Wnr7k1Hn8T2FGxUQychwlzq/el+nJnC0njkpUukj5NkM85QA5tYWZ3mdnnzKyN\n8LvfYWa3AJvJmS0kNcUIHEmfAa4D2qn296LaiZ0SyZ7rCStn3gSWV/t+BnFcjwFHgf8B/wS+A7QA\n2+N4twJjUuf/lLDa4QBwXar/mvjleRO4L9U/AtgQ+3cBk6s95hJ2mAecJayA2wfsjf/nF+bQZ5FM\nmQAAAGxJREFUFlfG8b8M7AdWxP7c2aLALgvoSnrnzhbAlNTvoz15DlbbFl645ziO45RFLU5JOY7j\nODWIOwzHcRynLNxhOI7jOGXhDsNxHMcpC3cYjuM4Tlm4w3Acx3HKwh2G4ziOUxbuMBzHcZyy+D/f\nvUHowUoLvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12be30860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Example script showing how to use stateful RNNs\n",
    "to model long sequences efficiently.\n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "\n",
    "# since we are using stateful rnn tsteps can be set to 1\n",
    "tsteps = 1\n",
    "batch_size = 25\n",
    "epochs = 25\n",
    "# number of elements ahead that are used to make the prediction\n",
    "lahead = 1\n",
    "\n",
    "\n",
    "def gen_cosine_amp(amp=100, period=1000, x0=0, xn=50000, step=1, k=0.0001):\n",
    "    \"\"\"Generates an absolute cosine time series with the amplitude\n",
    "    exponentially decreasing\n",
    "    Arguments:\n",
    "        amp: amplitude of the cosine function\n",
    "        period: period of the cosine function\n",
    "        x0: initial x of the time series\n",
    "        xn: final x of the time series\n",
    "        step: step of the time series discretization\n",
    "        k: exponential rate\n",
    "    \"\"\"\n",
    "    cos = np.zeros(((xn - x0) * step, 1, 1))\n",
    "    for i in range(len(cos)):\n",
    "        idx = x0 + i * step\n",
    "        cos[i, 0, 0] = amp * np.cos(2 * np.pi * idx / period)\n",
    "        cos[i, 0, 0] = cos[i, 0, 0] * np.exp(-k * idx)\n",
    "    return cos\n",
    "\n",
    "\n",
    "print('Generating Data')\n",
    "cos = gen_cosine_amp()\n",
    "print('Input shape:', cos.shape)\n",
    "\n",
    "expected_output = np.zeros((len(cos), 1))\n",
    "for i in range(len(cos) - lahead):\n",
    "    expected_output[i, 0] = np.mean(cos[i + 1:i + lahead + 1])\n",
    "\n",
    "print('Output shape')\n",
    "print(expected_output.shape)\n",
    "\n",
    "print('Creating Model')\n",
    "model = Sequential()\n",
    "model.add(LSTM(50,\n",
    "               batch_input_shape=(batch_size, tsteps, 1),\n",
    "               return_sequences=True,\n",
    "               stateful=True))\n",
    "model.add(LSTM(50,\n",
    "               batch_input_shape=(batch_size, tsteps, 1),\n",
    "               return_sequences=False,\n",
    "               stateful=True))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "print('Training')\n",
    "for i in range(epochs):\n",
    "    print('Epoch', i, '/', epochs)\n",
    "    model.fit(cos,\n",
    "              expected_output,\n",
    "              batch_size=batch_size,\n",
    "              verbose=1,\n",
    "              nb_epoch=1,\n",
    "              shuffle=False)\n",
    "    model.reset_states()\n",
    "\n",
    "print('Predicting')\n",
    "predicted_output = model.predict(cos, batch_size=batch_size)\n",
    "\n",
    "print('Plotting Results')\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(expected_output)\n",
    "plt.title('Expected')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(predicted_output)\n",
    "plt.title('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
